{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import sounddevice as sd\n",
    "from pystoi.stoi import stoi\n",
    "from librosa.core import stft, istft\n",
    "import os\n",
    "import h5py\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_path=os.getcwd()\n",
    "i = 1\n",
    "w = 3\n",
    "a = os.listdir(os.path.join(orig_path,'sec_mixed2_6_test'))\n",
    "a = natsorted(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t2_bwba6a_m24_brax9p\n",
      "t2_bwbn2s_m2_brif5p\n",
      "t2_bwigzs_m2_sbit3p\n",
      "t2_bwwn8a_m20_bbwe3p\n",
      "t2_lwafza_m2_pgaq8a\n",
      "t2_lwbf3p_m2_sgwc9n\n",
      "t2_lwbszs_m2_sgai5n\n",
      "t2_lwwf8a_m27_lgwd6n\n",
      "t2_lwws4s_m26_lbwi6a\n",
      "t2_pwad4a_m4_lrij9n\n",
      "t2_pwbd8a_m13_sgia9a\n",
      "t2_pwbk2a_m2_sria7p\n",
      "t2_pwij2s_m2_sgav6a\n",
      "t2_pwwq7n_m2_pgwlzs\n",
      "t2_swaizs_m22_lrib8s\n",
      "t2_swib3p_m16_bbaq7p\n",
      "t2_swin9n_m20_pbim6s\n",
      "t2_swwc4s_m9_bgis9a\n",
      "t2_swwv6s_m22_lgad3n\n",
      "t2_swwv8a_m4_lgal6s\n",
      "t2_bwba6a_m24_brax9p\n",
      "t2_bwbn2s_m2_brif5p\n",
      "t2_bwigzs_m2_sbit3p\n",
      "t2_bwwn8a_m20_bbwe3p\n",
      "t2_lwafza_m2_pgaq8a\n",
      "t2_lwbf3p_m2_sgwc9n\n",
      "t2_lwbszs_m2_sgai5n\n",
      "t2_lwwf8a_m27_lgwd6n\n",
      "t2_lwws4s_m26_lbwi6a\n",
      "t2_pwad4a_m4_lrij9n\n",
      "t2_pwbd8a_m13_sgia9a\n",
      "t2_pwbk2a_m2_sria7p\n",
      "t2_pwij2s_m2_sgav6a\n",
      "t2_pwwq7n_m2_pgwlzs\n",
      "t2_swaizs_m22_lrib8s\n",
      "t2_swib3p_m16_bbaq7p\n",
      "t2_swin9n_m20_pbim6s\n",
      "t2_swwc4s_m9_bgis9a\n",
      "t2_swwv6s_m22_lgad3n\n",
      "t2_swwv8a_m4_lgal6s\n",
      "t2_bwba6a_m24_brax9p\n",
      "t2_bwbn2s_m2_brif5p\n",
      "t2_bwigzs_m2_sbit3p\n",
      "t2_bwwn8a_m20_bbwe3p\n",
      "t2_lwafza_m2_pgaq8a\n",
      "t2_lwbf3p_m2_sgwc9n\n",
      "t2_lwbszs_m2_sgai5n\n",
      "t2_lwwf8a_m27_lgwd6n\n",
      "t2_lwws4s_m26_lbwi6a\n",
      "t2_pwad4a_m4_lrij9n\n",
      "t2_pwbd8a_m13_sgia9a\n",
      "t2_pwbk2a_m2_sria7p\n",
      "t2_pwij2s_m2_sgav6a\n",
      "t2_pwwq7n_m2_pgwlzs\n",
      "t2_swaizs_m22_lrib8s\n",
      "t2_swib3p_m16_bbaq7p\n",
      "t2_swin9n_m20_pbim6s\n",
      "t2_swwc4s_m9_bgis9a\n",
      "t2_swwv6s_m22_lgad3n\n",
      "t2_swwv8a_m4_lgal6s\n",
      "t2_bwba6a_m24_brax9p\n",
      "t2_bwbn2s_m2_brif5p\n",
      "t2_bwigzs_m2_sbit3p\n",
      "t2_bwwn8a_m20_bbwe3p\n",
      "t2_lwafza_m2_pgaq8a\n",
      "t2_lwbf3p_m2_sgwc9n\n",
      "t2_lwbszs_m2_sgai5n\n",
      "t2_lwwf8a_m27_lgwd6n\n",
      "t2_lwws4s_m26_lbwi6a\n",
      "t2_pwad4a_m4_lrij9n\n",
      "t2_pwbd8a_m13_sgia9a\n",
      "t2_pwbk2a_m2_sria7p\n",
      "t2_pwij2s_m2_sgav6a\n",
      "t2_pwwq7n_m2_pgwlzs\n",
      "t2_swaizs_m22_lrib8s\n",
      "t2_swib3p_m16_bbaq7p\n",
      "t2_swin9n_m20_pbim6s\n",
      "t2_swwc4s_m9_bgis9a\n",
      "t2_swwv6s_m22_lgad3n\n",
      "t2_swwv8a_m4_lgal6s\n",
      "t2_bwba6a_m24_brax9p\n",
      "t2_bwbn2s_m2_brif5p\n",
      "t2_bwigzs_m2_sbit3p\n",
      "t2_bwwn8a_m20_bbwe3p\n",
      "t2_lwafza_m2_pgaq8a\n",
      "t2_lwbf3p_m2_sgwc9n\n",
      "t2_lwbszs_m2_sgai5n\n",
      "t2_lwwf8a_m27_lgwd6n\n",
      "t2_lwws4s_m26_lbwi6a\n",
      "t2_pwad4a_m4_lrij9n\n",
      "t2_pwbd8a_m13_sgia9a\n",
      "t2_pwbk2a_m2_sria7p\n",
      "t2_pwij2s_m2_sgav6a\n",
      "t2_pwwq7n_m2_pgwlzs\n",
      "t2_swaizs_m22_lrib8s\n",
      "t2_swib3p_m16_bbaq7p\n",
      "t2_swin9n_m20_pbim6s\n",
      "t2_swwc4s_m9_bgis9a\n",
      "t2_swwv6s_m22_lgad3n\n",
      "t2_swwv8a_m4_lgal6s\n",
      "t2_bwba6a_m24_brax9p\n",
      "t2_bwbn2s_m2_brif5p\n",
      "t2_bwigzs_m2_sbit3p\n",
      "t2_bwwn8a_m20_bbwe3p\n",
      "t2_lwafza_m2_pgaq8a\n",
      "t2_lwbf3p_m2_sgwc9n\n",
      "t2_lwbszs_m2_sgai5n\n",
      "t2_lwwf8a_m27_lgwd6n\n",
      "t2_lwws4s_m26_lbwi6a\n",
      "t2_pwad4a_m4_lrij9n\n",
      "t2_pwbd8a_m13_sgia9a\n",
      "t2_pwbk2a_m2_sria7p\n",
      "t2_pwij2s_m2_sgav6a\n",
      "t2_pwwq7n_m2_pgwlzs\n",
      "t2_swaizs_m22_lrib8s\n",
      "t2_swib3p_m16_bbaq7p\n",
      "t2_swin9n_m20_pbim6s\n",
      "t2_swwc4s_m9_bgis9a\n",
      "t2_swwv6s_m22_lgad3n\n",
      "t2_swwv8a_m4_lgal6s\n"
     ]
    }
   ],
   "source": [
    "a = os.listdir(os.path.join(orig_path,'sec_mixed2_6_test'))\n",
    "a = natsorted(a)\n",
    "for filename in a:\n",
    "    if filename!='clean':\n",
    "        b = os.listdir(os.path.join(orig_path,'sec_mixed2_6_test',filename))\n",
    "        b = natsorted(b)\n",
    "        if not os.path.exists(os.path.join(orig_path,'test_log',filename)):\n",
    "            os.mkdir(os.path.join(orig_path,'test_log',filename))\n",
    "        if not os.path.exists(os.path.join(orig_path,'test_phase',filename)):\n",
    "            os.mkdir(os.path.join(orig_path,'test_phase',filename))\n",
    "        for filename2 in b:\n",
    "            wav_data, sr = librosa.load(os.path.join(orig_path,'sec_mixed2_6_test')+\"/\"+filename+'/'+filename2, sr=16000) \n",
    "            framed_data=librosa.core.stft(wav_data, n_fft=512, hop_length=256, win_length=512, window='hann')\n",
    "            abslt=np.absolute(framed_data)**2\n",
    "            dft_signal=np.log10(abslt+1e-7*np.ones(np.shape(abslt)))\n",
    "            for i in range(m.floor(w/2)):\n",
    "                dft_signal=np.insert(dft_signal,0,0,axis = 1)\n",
    "            data_phase=np.angle(framed_data)   \n",
    "            print(str(filename2.replace('.wav','')))\n",
    "            np.savetxt('test_log/'+str(filename)+'/'+str(filename2.replace('.wav',''))+'.txt', dft_signal.T, delimiter=',')\n",
    "            np.savetxt('test_phase/'+str(filename)+'/'+str(filename2.replace('.wav',''))+'.txt', data_phase.T, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = os.listdir(os.path.join(orig_path,'sec_mixed2_6_test'))\n",
    "a = natsorted(a)\n",
    "for filename in a:\n",
    "    if filename!='clean':\n",
    "        b = os.listdir(os.path.join(orig_path,'sec_mixed2_6_test',filename))\n",
    "        b = natsorted(b)\n",
    "        if not os.path.exists(os.path.join(orig_path,'test_log2',filename)):\n",
    "            os.mkdir(os.path.join(orig_path,'test_log2',filename))\n",
    "        if not os.path.exists(os.path.join(orig_path,'test_phase2',filename)):\n",
    "            os.mkdir(os.path.join(orig_path,'test_phase2',filename))\n",
    "        for filename2 in b:\n",
    "            wav_data, sr = librosa.load(os.path.join(orig_path,'sec_mixed2_6_test',filename,filename2), sr=16000) \n",
    "            framed_data=librosa.core.stft(wav_data, n_fft=512, hop_length=256, win_length=512, window='hann')\n",
    "            abslt=np.absolute(framed_data)**2\n",
    "            dft_signal=np.log10(abslt+1e-7*np.ones(np.shape(abslt)))\n",
    "            data_phase=np.angle(framed_data)    \n",
    "            np.savetxt(os.path.join('test_log2',filename,str(filename2.replace('.wav','.txt'))), dft_signal.T, delimiter=',')\n",
    "            np.savetxt(os.path.join('test_phase2',filename,str(filename2.replace('.wav','.txt'))), data_phase.T, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = os.listdir(os.path.join(orig_path,'sec_mixed2_6_test'))\n",
    "a = natsorted(a)\n",
    "for filename in a:\n",
    "    if filename=='clean':\n",
    "        b = os.listdir(os.path.join(orig_path,'sec_mixed2_6_test',filename))\n",
    "        b = natsorted(b)\n",
    "        if not os.path.exists(os.path.join(orig_path,'test_log',filename)):\n",
    "            os.mkdir(os.path.join(orig_path,'test_log',filename))\n",
    "        for filename2 in b:\n",
    "            wav_data, sr = librosa.load(os.path.join(orig_path,'sec_mixed2_6_test',filename,filename2), sr=16000)   \n",
    "            np.savetxt(os.path.join('test_log',str(filename),str(filename2.replace('.wav','.txt'))), wav_data, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = os.listdir(os.path.join(orig_path,'sec_mixed2_6_test'))\n",
    "a = natsorted(a)\n",
    "clean=[]\n",
    "f = h5py.File('clean_data'+'.hdf5', 'w')\n",
    "d = f.create_dataset('clean_data', (0,257),maxshape=(None,257), dtype='f', chunks=True)\n",
    "for filename in a:\n",
    "    if filename=='clean':\n",
    "        b = os.listdir(os.path.join(orig_path,'sec_mixed2_6_test',filename))\n",
    "        b = natsorted(b)\n",
    "        for i in range(len(a)-1):\n",
    "            for filename2 in b:\n",
    "                wav_data, sr = librosa.load(os.path.join(orig_path,'sec_mixed2_6_test',filename,filename2), sr=16000)   \n",
    "                framed_data=librosa.core.stft(wav_data, n_fft=512, hop_length=256, win_length=512, window='hann')\n",
    "                abslt=np.absolute(framed_data)**2\n",
    "                dft_signal=np.log10(abslt+1e-7*np.ones(np.shape(abslt)))\n",
    "#                 clean.append(dft_signal.T)\n",
    "                d.resize(d.shape[0]+dft_signal.shape[1], axis=0)   \n",
    "                d[-1*dft_signal.shape[1]:] = dft_signal.T\n",
    "f.close()\n",
    "# x=1\n",
    "# hf = h5py.File('clean_data.h5', 'w')\n",
    "# hf.create_dataset('clean_data', data=x)\n",
    "# hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t2_bwba6a_m24_brax9p.wav',\n",
       " 't2_bwbn2s_m2_brif5p.wav',\n",
       " 't2_bwigzs_m2_sbit3p.wav',\n",
       " 't2_bwwn8a_m20_bbwe3p.wav',\n",
       " 't2_lwafza_m2_pgaq8a.wav',\n",
       " 't2_lwbf3p_m2_sgwc9n.wav',\n",
       " 't2_lwbszs_m2_sgai5n.wav',\n",
       " 't2_lwwf8a_m27_lgwd6n.wav',\n",
       " 't2_lwws4s_m26_lbwi6a.wav',\n",
       " 't2_pwad4a_m4_lrij9n.wav',\n",
       " 't2_pwbd8a_m13_sgia9a.wav',\n",
       " 't2_pwbk2a_m2_sria7p.wav',\n",
       " 't2_pwij2s_m2_sgav6a.wav',\n",
       " 't2_pwwq7n_m2_pgwlzs.wav',\n",
       " 't2_swaizs_m22_lrib8s.wav',\n",
       " 't2_swib3p_m16_bbaq7p.wav',\n",
       " 't2_swin9n_m20_pbim6s.wav',\n",
       " 't2_swwc4s_m9_bgis9a.wav',\n",
       " 't2_swwv6s_m22_lgad3n.wav',\n",
       " 't2_swwv8a_m4_lgal6s.wav']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not a dataset (not a dataset)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4d0b3466c458>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ftr_refrmd_test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\dataset.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;34m\"\"\"Numpy-style shape tuple giving dataset dimensions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwith_phil\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.shape.__get__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.shape.__get__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.get_space\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Not a dataset (not a dataset)"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "h5f = h5py.File('ftr_refrmd_test.hdf5','r')\n",
    "x = h5f['ftr_refrmd_test']\n",
    "h5f.close()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n"
     ]
    }
   ],
   "source": [
    "import math as m\n",
    "import numpy as np\n",
    "import h5py\n",
    "w = 3\n",
    "orig_path=os.getcwd()\n",
    "i = 1\n",
    "# tot_mean=np.loadtxt('mean.txt')\n",
    "# tot_std=np.loadtxt('std.txt')\n",
    "a = os.listdir(os.path.join(orig_path,'test_log'))\n",
    "a = natsorted(a)\n",
    "refrmd_file='ftr_refrmd_test'\n",
    "# f.close()\n",
    "f = h5py.File(refrmd_file+'.hdf5', 'w')\n",
    "d = f.create_dataset(refrmd_file, (0,257*w),maxshape=(None,257*w), dtype='f', chunks=True)\n",
    "ftr_refrmd=[]\n",
    "for filename in a:\n",
    "    if filename!='clean':\n",
    "        b = natsorted(b)\n",
    "        b = os.listdir(os.path.join(orig_path,'test_log',filename))\n",
    "        if not os.path.exists(os.path.join(orig_path,'ftr_refrmd_test',filename)):\n",
    "            os.mkdir(os.path.join(orig_path,'ftr_refrmd_test',filename))\n",
    "        for filename2 in b:\n",
    "            ftr=np.loadtxt(os.path.join(orig_path,'test_log',filename,filename2),delimiter=',')\n",
    "            ftr_refrmd=[]\n",
    "            for i in range(m.floor(w/2)):\n",
    "                p=-m.floor(w/2)\n",
    "                temp = []\n",
    "                for j in range(w):\n",
    "                    if np.all(ftr[i]==0):\n",
    "                        break\n",
    "                    temp.extend(ftr[i+p+j])\n",
    "                if np.any(temp!=[]):\n",
    "                    ftr_refrmd.append(temp)\n",
    "            for i in range(m.floor(w/2),ftr.shape[0]-m.floor(w/2)-1):\n",
    "                k=-m.floor(w/2)\n",
    "                temp = []\n",
    "                for j in range(w):\n",
    "                    if np.all(ftr[i]==0):\n",
    "                        break\n",
    "                    temp.extend(ftr[i+k])\n",
    "                    k=k+1\n",
    "                if np.any(temp!=[]):\n",
    "                    ftr_refrmd.append(temp)\n",
    "                if i%1000==0:\n",
    "                    print(i)\n",
    "            for i in range(ftr.shape[0]-m.floor(w/2)-1,ftr.shape[0]):\n",
    "                p=-m.floor(w/2)\n",
    "                temp = []\n",
    "                for j in range(w):\n",
    "                    if np.all(ftr[i]==0):\n",
    "                        break\n",
    "                    if j>m.floor(w/2)+(ftr.shape[0]-i)-1:\n",
    "                        temp.extend(np.zeros(ftr[ftr.shape[0]-1].shape))\n",
    "                    else:\n",
    "                        temp.extend(ftr[i+p+j])\n",
    "                if np.any(temp!=[]):\n",
    "                    ftr_refrmd.append(temp)\n",
    "            print(len(ftr_refrmd[0]))\n",
    "#             ftr_refrmd=(ftr_refrmd-tot_mean)/tot_std\n",
    "            np.savetxt(os.path.join('ftr_refrmd_test',str(filename),str(filename2.replace('.wav','.txt'))), ftr_refrmd, delimiter=',')\n",
    "            \n",
    "# d.resize(d.shape[0]+len(ftr_refrmd), axis=0)   \n",
    "# d[-1*len(ftr_refrmd):] = ftr_refrmd\n",
    "# ftr_refrmd=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13692"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ftr_refrmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h5py' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-db37f775febe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mh5f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ftr_refrmd_test.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ftr_refrmd_test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'h5py' is not defined"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('ftr_refrmd_test.hdf5','r')\n",
    "x = h5f['ftr_refrmd_test'][0:]\n",
    "h5f.close()\n",
    "x.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "771"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ftr_refrmd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
