{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import sounddevice as sd\n",
    "from pystoi.stoi import stoi\n",
    "from librosa.core import stft, istft\n",
    "import os\n",
    "import h5py\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "i = 1\n",
    "w = 3\n",
    "a = os.listdir(os.path.join(orig_path,'sec_mixed2_6_test'))\n",
    "a = natsorted(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t2_bwba6a_m24_brax9p\n",
      "t2_bwbn2s_m2_brif5p\n",
      "t2_bwigzs_m2_sbit3p\n",
      "t2_bwwn8a_m20_bbwe3p\n",
      "t2_lwafza_m2_pgaq8a\n",
      "t2_lwbf3p_m2_sgwc9n\n",
      "t2_lwbszs_m2_sgai5n\n",
      "t2_lwwf8a_m27_lgwd6n\n",
      "t2_lwws4s_m26_lbwi6a\n",
      "t2_pwad4a_m4_lrij9n\n",
      "t2_pwbd8a_m13_sgia9a\n",
      "t2_pwbk2a_m2_sria7p\n",
      "t2_pwij2s_m2_sgav6a\n",
      "t2_pwwq7n_m2_pgwlzs\n",
      "t2_swaizs_m22_lrib8s\n",
      "t2_swib3p_m16_bbaq7p\n",
      "t2_swin9n_m20_pbim6s\n",
      "t2_swwc4s_m9_bgis9a\n",
      "t2_swwv6s_m22_lgad3n\n",
      "t2_swwv8a_m4_lgal6s\n",
      "t2_bwba6a_m24_brax9p\n",
      "t2_bwbn2s_m2_brif5p\n",
      "t2_bwigzs_m2_sbit3p\n",
      "t2_bwwn8a_m20_bbwe3p\n",
      "t2_lwafza_m2_pgaq8a\n",
      "t2_lwbf3p_m2_sgwc9n\n",
      "t2_lwbszs_m2_sgai5n\n",
      "t2_lwwf8a_m27_lgwd6n\n",
      "t2_lwws4s_m26_lbwi6a\n",
      "t2_pwad4a_m4_lrij9n\n",
      "t2_pwbd8a_m13_sgia9a\n",
      "t2_pwbk2a_m2_sria7p\n",
      "t2_pwij2s_m2_sgav6a\n",
      "t2_pwwq7n_m2_pgwlzs\n",
      "t2_swaizs_m22_lrib8s\n",
      "t2_swib3p_m16_bbaq7p\n",
      "t2_swin9n_m20_pbim6s\n",
      "t2_swwc4s_m9_bgis9a\n",
      "t2_swwv6s_m22_lgad3n\n",
      "t2_swwv8a_m4_lgal6s\n",
      "t2_bwba6a_m24_brax9p\n",
      "t2_bwbn2s_m2_brif5p\n",
      "t2_bwigzs_m2_sbit3p\n",
      "t2_bwwn8a_m20_bbwe3p\n",
      "t2_lwafza_m2_pgaq8a\n",
      "t2_lwbf3p_m2_sgwc9n\n",
      "t2_lwbszs_m2_sgai5n\n",
      "t2_lwwf8a_m27_lgwd6n\n",
      "t2_lwws4s_m26_lbwi6a\n",
      "t2_pwad4a_m4_lrij9n\n",
      "t2_pwbd8a_m13_sgia9a\n",
      "t2_pwbk2a_m2_sria7p\n",
      "t2_pwij2s_m2_sgav6a\n",
      "t2_pwwq7n_m2_pgwlzs\n",
      "t2_swaizs_m22_lrib8s\n",
      "t2_swib3p_m16_bbaq7p\n",
      "t2_swin9n_m20_pbim6s\n",
      "t2_swwc4s_m9_bgis9a\n",
      "t2_swwv6s_m22_lgad3n\n",
      "t2_swwv8a_m4_lgal6s\n",
      "t2_bwba6a_m24_brax9p\n",
      "t2_bwbn2s_m2_brif5p\n",
      "t2_bwigzs_m2_sbit3p\n",
      "t2_bwwn8a_m20_bbwe3p\n",
      "t2_lwafza_m2_pgaq8a\n",
      "t2_lwbf3p_m2_sgwc9n\n",
      "t2_lwbszs_m2_sgai5n\n",
      "t2_lwwf8a_m27_lgwd6n\n",
      "t2_lwws4s_m26_lbwi6a\n",
      "t2_pwad4a_m4_lrij9n\n",
      "t2_pwbd8a_m13_sgia9a\n",
      "t2_pwbk2a_m2_sria7p\n",
      "t2_pwij2s_m2_sgav6a\n",
      "t2_pwwq7n_m2_pgwlzs\n",
      "t2_swaizs_m22_lrib8s\n",
      "t2_swib3p_m16_bbaq7p\n",
      "t2_swin9n_m20_pbim6s\n",
      "t2_swwc4s_m9_bgis9a\n",
      "t2_swwv6s_m22_lgad3n\n",
      "t2_swwv8a_m4_lgal6s\n",
      "t2_bwba6a_m24_brax9p\n",
      "t2_bwbn2s_m2_brif5p\n",
      "t2_bwigzs_m2_sbit3p\n",
      "t2_bwwn8a_m20_bbwe3p\n",
      "t2_lwafza_m2_pgaq8a\n",
      "t2_lwbf3p_m2_sgwc9n\n",
      "t2_lwbszs_m2_sgai5n\n",
      "t2_lwwf8a_m27_lgwd6n\n",
      "t2_lwws4s_m26_lbwi6a\n",
      "t2_pwad4a_m4_lrij9n\n",
      "t2_pwbd8a_m13_sgia9a\n",
      "t2_pwbk2a_m2_sria7p\n",
      "t2_pwij2s_m2_sgav6a\n",
      "t2_pwwq7n_m2_pgwlzs\n",
      "t2_swaizs_m22_lrib8s\n",
      "t2_swib3p_m16_bbaq7p\n",
      "t2_swin9n_m20_pbim6s\n",
      "t2_swwc4s_m9_bgis9a\n",
      "t2_swwv6s_m22_lgad3n\n",
      "t2_swwv8a_m4_lgal6s\n",
      "t2_bwba6a_m24_brax9p\n",
      "t2_bwbn2s_m2_brif5p\n",
      "t2_bwigzs_m2_sbit3p\n",
      "t2_bwwn8a_m20_bbwe3p\n",
      "t2_lwafza_m2_pgaq8a\n",
      "t2_lwbf3p_m2_sgwc9n\n",
      "t2_lwbszs_m2_sgai5n\n",
      "t2_lwwf8a_m27_lgwd6n\n",
      "t2_lwws4s_m26_lbwi6a\n",
      "t2_pwad4a_m4_lrij9n\n",
      "t2_pwbd8a_m13_sgia9a\n",
      "t2_pwbk2a_m2_sria7p\n",
      "t2_pwij2s_m2_sgav6a\n",
      "t2_pwwq7n_m2_pgwlzs\n",
      "t2_swaizs_m22_lrib8s\n",
      "t2_swib3p_m16_bbaq7p\n",
      "t2_swin9n_m20_pbim6s\n",
      "t2_swwc4s_m9_bgis9a\n",
      "t2_swwv6s_m22_lgad3n\n",
      "t2_swwv8a_m4_lgal6s\n"
     ]
    }
   ],
   "source": [
    "raw_folder = 'sec_mixed2_6_test'\n",
    "log_folder = 'test_log_wav_norm'\n",
    "phase_folder = 'test_phase_wav_norm'\n",
    "a = os.listdir(os.path.join(orig_path,raw_folder))\n",
    "a = natsorted(a)\n",
    "if not os.path.exists(os.path.normpath(os.path.join(orig_path,log_folder))):\n",
    "    os.mkdir(os.path.normpath(os.path.join(orig_path,log_folder)))\n",
    "if not os.path.exists(os.path.normpath(os.path.join(orig_path,phase_folder))):\n",
    "    os.mkdir(os.path.normpath(os.path.join(orig_path,phase_folder)))\n",
    "for filename in a:\n",
    "    if filename!='clean':\n",
    "        b = os.listdir(os.path.normpath(os.path.join(orig_path,raw_folder,filename)))\n",
    "        b = natsorted(b)\n",
    "        if not os.path.exists(os.path.normpath(os.path.join(orig_path,log_folder,filename))):\n",
    "            os.mkdir(os.path.normpath(os.path.join(orig_path,log_folder,filename)))\n",
    "        if not os.path.exists(os.path.join(orig_path,phase_folder,filename)):\n",
    "            os.mkdir(os.path.normpath(os.path.join(orig_path,phase_folder,filename)))\n",
    "        for filename2 in b:\n",
    "            wav_data, sr = librosa.load(os.path.join(orig_path,raw_folder)+\"/\"+filename+'/'+filename2, sr=16000)\n",
    "            max_wav=np.max(wav_data)\n",
    "            wav_data = wav_data/max_wav\n",
    "            framed_data=librosa.core.stft(wav_data, n_fft=512, hop_length=256, win_length=512, window='hann')\n",
    "            abslt=np.absolute(framed_data)**2\n",
    "            dft_signal=np.log10(abslt+1e-7*np.ones(np.shape(abslt)))\n",
    "            for i in range(m.floor(w/2)):\n",
    "                dft_signal=np.insert(dft_signal,0,0,axis = 1)\n",
    "            data_phase=np.angle(framed_data)   \n",
    "            print(str(filename2.replace('.wav','')))\n",
    "            np.savetxt(os.path.join(orig_path,log_folder,str(filename),str(filename2.replace('.wav','.txt'))), dft_signal.T, delimiter=',')\n",
    "            np.savetxt(os.path.join(orig_path,phase_folder,str(filename),str(filename2.replace('.wav','.txt'))), data_phase.T, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_folder = 'sec_mixed2_6_test'\n",
    "log_folder = 'test_log2_wav_norm'\n",
    "phase_folder = 'test_phase2_wav_norm'\n",
    "a = os.listdir(os.path.join(orig_path,raw_folder))\n",
    "a = natsorted(a)\n",
    "if not os.path.exists(os.path.normpath(os.path.join(orig_path,log_folder))):\n",
    "    os.mkdir(os.path.normpath(os.path.join(orig_path,log_folder)))\n",
    "if not os.path.exists(os.path.normpath(os.path.join(orig_path,phase_folder))):\n",
    "    os.mkdir(os.path.normpath(os.path.join(orig_path,phase_folder)))\n",
    "for filename in a:\n",
    "    if filename!='clean':\n",
    "        b = os.listdir(os.path.join(orig_path,raw_folder,filename))\n",
    "        b = natsorted(b)\n",
    "        if not os.path.exists(os.path.join(orig_path,log_folder,filename)):\n",
    "            os.mkdir(os.path.join(orig_path,log_folder,filename))\n",
    "        if not os.path.exists(os.path.join(orig_path,phase_folder ,filename)):\n",
    "            os.mkdir(os.path.join(orig_path,phase_folder ,filename))\n",
    "        for filename2 in b:\n",
    "            wav_data, sr = librosa.load(os.path.join(orig_path,raw_folder,filename,filename2), sr=16000) \n",
    "            max_wav=np.max(wav_data)\n",
    "            wav_data = wav_data/max_wav\n",
    "            framed_data=librosa.core.stft(wav_data, n_fft=512, hop_length=256, win_length=512, window='hann')\n",
    "            abslt=np.absolute(framed_data)**2\n",
    "            dft_signal=np.log10(abslt+1e-7*np.ones(np.shape(abslt)))\n",
    "            data_phase=np.angle(framed_data)    \n",
    "            np.savetxt(os.path.join(orig_path,log_folder,filename,str(filename2.replace('.wav','.txt'))), dft_signal.T, delimiter=',')\n",
    "            np.savetxt(os.path.join(orig_path,phase_folder ,filename,str(filename2.replace('.wav','.txt'))), data_phase.T, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_folder = 'sec_mixed2_6_test'\n",
    "log_folder = 'test_log_wav_norm'\n",
    "phase_folder = 'test_phase_wav_norm'\n",
    "a = os.listdir(os.path.join(orig_path,raw_folder))\n",
    "a = natsorted(a)\n",
    "for filename in a:\n",
    "    if filename=='clean':\n",
    "        b = os.listdir(os.path.join(orig_path,raw_folder,filename))\n",
    "        b = natsorted(b)\n",
    "        if not os.path.exists(os.path.join(orig_path,log_folder,filename)):\n",
    "            os.mkdir(os.path.join(orig_path,log_folder,filename))\n",
    "        for filename2 in b:\n",
    "            wav_data, sr = librosa.load(os.path.join(orig_path,raw_folder,filename,filename2), sr=16000)  \n",
    "            max_wav=np.max(wav_data)\n",
    "            wav_data = wav_data/max_wav\n",
    "            np.savetxt(os.path.join(orig_path,log_folder,str(filename),str(filename2.replace('.wav','.txt'))), wav_data, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to truncate a file which is already open)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-755ea3a59fa8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnatsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m257\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m257\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (unable to truncate a file which is already open)"
     ]
    }
   ],
   "source": [
    "raw_folder = 'sec_mixed2_6_test'\n",
    "clean_filename = 'clean_data_wav_norm'\n",
    "clean_path = os.path.normpath(os.path.join(orig_path,clean_filename))\n",
    "a = os.listdir(os.path.normpath(os.path.join(orig_path,raw_folder)))\n",
    "a = natsorted(a)\n",
    "clean=[]\n",
    "f = h5py.File(clean_path+'.hdf5', 'w')\n",
    "d = f.create_dataset(clean_filename, (0,257),maxshape=(None,257), dtype='f', chunks=True)\n",
    "for filename in a:\n",
    "    if filename=='clean':\n",
    "        b = os.listdir(os.path.join(orig_path,raw_folder,filename))\n",
    "        b = natsorted(b)\n",
    "        for i in range(len(a)-1):\n",
    "            for filename2 in b:\n",
    "                wav_data, sr = librosa.load(os.path.join(orig_path,raw_folder,filename,filename2), sr=16000)   \n",
    "                max_wav=np.max(wav_data)\n",
    "                wav_data = wav_data/max_wav\n",
    "                framed_data=librosa.core.stft(wav_data, n_fft=512, hop_length=256, win_length=512, window='hann')\n",
    "                abslt=np.absolute(framed_data)**2\n",
    "                dft_signal=np.log10(abslt+1e-7*np.ones(np.shape(abslt)))\n",
    "#                 clean.append(dft_signal.T)\n",
    "                d.resize(d.shape[0]+dft_signal.shape[1], axis=0)   \n",
    "                d[-1*dft_signal.shape[1]:] = dft_signal.T\n",
    "f.close()\n",
    "# x=1\n",
    "# hf = h5py.File('clean_data.h5', 'w')\n",
    "# hf.create_dataset('clean_data', data=x)\n",
    "# hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "h5f = h5py.File('ftr_refrmd_test.hdf5','r')\n",
    "x = h5f['ftr_refrmd_test']\n",
    "h5f.close()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n"
     ]
    }
   ],
   "source": [
    "import math as m\n",
    "import numpy as np\n",
    "import h5py\n",
    "w = 3\n",
    "i = 1\n",
    "refrmd_file = 'ftr_refrmd_test_wav_norm'\n",
    "log_folder = 'test_log_wav_norm'\n",
    "phase_folder = 'test_phase_wav_norm'\n",
    "refrmd_path = os.path.normpath(os.path.join(orig_path,refrmd_file))\n",
    "if not os.path.exists(os.path.normpath(os.path.join(orig_path,refrmd_file))):\n",
    "    os.mkdir(os.path.normpath(os.path.join(orig_path,refrmd_file)))\n",
    "# tot_mean=np.loadtxt('mean.txt')\n",
    "# tot_std=np.loadtxt('std.txt')\n",
    "a = os.listdir(os.path.join(orig_path,log_folder))\n",
    "a = natsorted(a)\n",
    "# f.close()\n",
    "f = h5py.File(refrmd_path+'.hdf5', 'w')\n",
    "d = f.create_dataset(refrmd_file, (0,257*w),maxshape=(None,257*w), dtype='f', chunks=True)\n",
    "ftr_refrmd=[]\n",
    "for filename in a:\n",
    "    if filename!='clean':\n",
    "        b = natsorted(b)\n",
    "        b = os.listdir(os.path.join(orig_path,log_folder,filename))\n",
    "        if not os.path.exists(os.path.join(orig_path,refrmd_file,filename)):\n",
    "            os.mkdir(os.path.join(orig_path,refrmd_file,filename))\n",
    "        for filename2 in b:\n",
    "            ftr=np.loadtxt(os.path.join(orig_path,log_folder,filename,filename2),delimiter=',')\n",
    "#             ftr_refrmd=[]\n",
    "            for i in range(m.floor(w/2)):\n",
    "                p=-m.floor(w/2)\n",
    "                temp = []\n",
    "                for j in range(w):\n",
    "                    if np.all(ftr[i]==0):\n",
    "                        break\n",
    "                    temp.extend(ftr[i+p+j])\n",
    "                if np.any(temp!=[]):\n",
    "                    ftr_refrmd.append(temp)\n",
    "            for i in range(m.floor(w/2),ftr.shape[0]-m.floor(w/2)-1):\n",
    "                k=-m.floor(w/2)\n",
    "                temp = []\n",
    "                for j in range(w):\n",
    "                    if np.all(ftr[i]==0):\n",
    "                        break\n",
    "                    temp.extend(ftr[i+k])\n",
    "                    k=k+1\n",
    "                if np.any(temp!=[]):\n",
    "                    ftr_refrmd.append(temp)\n",
    "                if i%1000==0:\n",
    "                    print(i)\n",
    "            for i in range(ftr.shape[0]-m.floor(w/2)-1,ftr.shape[0]):\n",
    "                p=-m.floor(w/2)\n",
    "                temp = []\n",
    "                for j in range(w):\n",
    "                    if np.all(ftr[i]==0):\n",
    "                        break\n",
    "                    if j>m.floor(w/2)+(ftr.shape[0]-i)-1:\n",
    "                        temp.extend(np.zeros(ftr[ftr.shape[0]-1].shape))\n",
    "                    else:\n",
    "                        temp.extend(ftr[i+p+j])\n",
    "                if np.any(temp!=[]):\n",
    "                    ftr_refrmd.append(temp)\n",
    "            print(len(ftr_refrmd[0]))\n",
    "#             ftr_refrmd=(ftr_refrmd-tot_mean)/tot_std\n",
    "#             np.savetxt(os.path.normpath(os.path.join(orig_path,refrmd_file,str(filename),str(filename2.replace('.wav','.txt')))), ftr_refrmd, delimiter=',')\n",
    "            \n",
    "d.resize(d.shape[0]+len(ftr_refrmd), axis=0)   \n",
    "d[-1*len(ftr_refrmd):] = ftr_refrmd\n",
    "ftr_refrmd=[]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serializing 13692 examples into D:\\studies\\university\\thesis\\speech_separation_codes\\du16\\donesomestuff\\tfrecord_files\\test_wav_norm\\filenum0.tfrecords\n",
      "Writing D:\\studies\\university\\thesis\\speech_separation_codes\\du16\\donesomestuff\\tfrecord_files\\test_wav_norm\\filenum0.tfrecords done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "__author__ = \"Sangwoong Yoon\"\n",
    "\n",
    "def np_to_tfrecords(X, Y, file_path_prefix, verbose=True):\n",
    "    \"\"\"\n",
    "    Converts a Numpy array (or two Numpy arrays) into a tfrecord file.\n",
    "    For supervised learning, feed training inputs to X and training labels to Y.\n",
    "    For unsupervised learning, only feed training inputs to X, and feed None to Y.\n",
    "    The length of the first dimensions of X and Y should be the number of samples.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy.ndarray of rank 2\n",
    "        Numpy array for training inputs. Its dtype should be float32, float64, or int64.\n",
    "        If X has a higher rank, it should be rshape before fed to this function.\n",
    "    Y : numpy.ndarray of rank 2 or None\n",
    "        Numpy array for training labels. Its dtype should be float32, float64, or int64.\n",
    "        None if there is no label array.\n",
    "    file_path_prefix : str\n",
    "        The path and name of the resulting tfrecord file to be generated, without '.tfrecords'\n",
    "    verbose : bool\n",
    "        If true, progress is reported.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If input type is not float (64 or 32) or int.\n",
    "    \n",
    "    \"\"\"\n",
    "    def _dtype_feature(ndarray):\n",
    "        \"\"\"match appropriate tf.train.Feature class with dtype of ndarray. \"\"\"\n",
    "        assert isinstance(ndarray, np.ndarray)\n",
    "        dtype_ = ndarray.dtype\n",
    "        if dtype_ == np.float64 or dtype_ == np.float32:\n",
    "            return lambda array: tf.train.Feature(float_list=tf.train.FloatList(value=array))\n",
    "        elif dtype_ == np.int64:\n",
    "            return lambda array: tf.train.Feature(int64_list=tf.train.Int64List(value=array))\n",
    "        else:  \n",
    "            raise ValueError(\"The input should be numpy ndarray. \\\n",
    "                               Instaed got {}\".format(ndarray.dtype))\n",
    "            \n",
    "    assert isinstance(X, np.ndarray)\n",
    "    assert len(X.shape) == 2  # If X has a higher rank, \n",
    "                               # it should be rshape before fed to this function.\n",
    "    assert isinstance(Y, np.ndarray) or Y is None\n",
    "    \n",
    "    # load appropriate tf.train.Feature class depending on dtype\n",
    "    dtype_feature_x = _dtype_feature(X)\n",
    "    if Y is not None:\n",
    "        assert X.shape[0] == Y.shape[0]\n",
    "        assert len(Y.shape) == 2\n",
    "        dtype_feature_y = _dtype_feature(Y)            \n",
    "    \n",
    "    # Generate tfrecord writer\n",
    "    result_tf_file = file_path_prefix + '.tfrecords'\n",
    "    writer = tf.python_io.TFRecordWriter(result_tf_file)\n",
    "    if verbose:\n",
    "        print(\"Serializing {:d} examples into {}\".format(X.shape[0], result_tf_file))\n",
    "        \n",
    "    # iterate over each sample,\n",
    "    # and serialize it as ProtoBuf.\n",
    "    for idx in range(X.shape[0]):\n",
    "        x = X[idx]\n",
    "        if Y is not None:\n",
    "            y = Y[idx]\n",
    "        \n",
    "        d_feature = {}\n",
    "        d_feature['X'] = dtype_feature_x(x)\n",
    "        if Y is not None:\n",
    "            d_feature['Y'] = dtype_feature_y(y)\n",
    "            \n",
    "        features = tf.train.Features(feature=d_feature)\n",
    "        example = tf.train.Example(features=features)\n",
    "        serialized = example.SerializeToString()\n",
    "        writer.write(serialized)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Writing {} done!\".format(result_tf_file))\n",
    "\n",
    "        \n",
    "#################################    \n",
    "##      Test and Use Cases     ##\n",
    "#################################\n",
    "import h5py\n",
    "load_size = 500000\n",
    "k = 0\n",
    "Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "write_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "input_name = 'ftr_refrmd_test_wav_norm'\n",
    "input_path = os.path.normpath(os.path.join(write_path,input_name))\n",
    "target_name = 'clean_data_wav_norm'\n",
    "target_path = os.path.normpath(os.path.join(write_path,target_name))\n",
    "h5f1 = h5py.File(input_path+'.hdf5','r')\n",
    "hh = h5py.File(target_path+'.hdf5', 'r')\n",
    "d=hh[target_name]\n",
    "data_len = d.shape[0]\n",
    "index = np.arange(0, data_len, load_size)\n",
    "tfrecord_name = 'test_wav_norm'\n",
    "if not os.path.exists(os.path.normpath(os.path.join(orig_path,'tfrecord_files',tfrecord_name))):\n",
    "    os.mkdir(os.path.normpath(os.path.join(orig_path,'tfrecord_files',tfrecord_name)))\n",
    "for I in index:\n",
    "    if data_len-I<load_size:\n",
    "        xx = h5f1[input_name][I:]\n",
    "        yy = hh[target_name][I:]\n",
    "    else:\n",
    "        xx = h5f1[input_name][I:I+load_size]\n",
    "        yy = hh[target_name][I:I+load_size]\n",
    "    np_to_tfrecords(xx, yy, os.path.normpath(os.path.join(Data_path,'tfrecord_files',tfrecord_name,'filenum'+str(k))), verbose=True)\n",
    "    k = k+1\n",
    "# 1-2. Check if the data is stored correctly\n",
    "# open the saved file and check the first entries\n",
    "# for serialized_example in tf.python_io.tf_record_iterator('test.tfrecords'):\n",
    "#     example = tf.train.Example()\n",
    "#     example.ParseFromString(serialized_example)\n",
    "#     x_1 = np.array(example.features.feature['X'].float_list.value)\n",
    "#     y_1 = np.array(example.features.feature['Y'].float_list.value)\n",
    "#     break\n",
    "\n",
    "# np_to_tfrecords(X, Y, file_path_prefix, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13692"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ftr_refrmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h5py' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-db37f775febe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mh5f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ftr_refrmd_test.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ftr_refrmd_test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'h5py' is not defined"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('ftr_refrmd_test.hdf5','r')\n",
    "x = h5f['ftr_refrmd_test'][0:]\n",
    "h5f.close()\n",
    "x.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "771"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ftr_refrmd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
