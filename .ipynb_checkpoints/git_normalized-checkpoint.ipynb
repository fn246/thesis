{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import csv\n",
    "import math as m\n",
    "from natsort import natsorted\n",
    "from sklearn import preprocessing\n",
    "import h5py\n",
    "#in this section the features for mixed voices are extracted.\n",
    "# orig_path=os.getcwd()\n",
    "i = 1\n",
    "Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "write_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff/10hdata'\n",
    "# mixed_folder = os.path.normpath(os.path.join(write_path,'mixed_10h'))\n",
    "# # f.close()\n",
    "# a = os.listdir(os.path.join(mixed_folder))\n",
    "# a = natsorted(a)\n",
    "# mixed_logname = 'mixed_log_10h_norm'\n",
    "# mixed_phasename = 'mixed_phase_10h_norm'\n",
    "# mixed_logpath = os.path.normpath(os.path.join(write_path,mixed_logname))\n",
    "# mixed_phasepath = os.path.normpath(os.path.join(write_path,mixed_phasename))\n",
    "\n",
    "# f = h5py.File(mixed_logpath+'.hdf5', 'w')\n",
    "# d = f.create_dataset(mixed_logname, (0,257),maxshape=(None,257), dtype='f', chunks=True)\n",
    "# # ff.close()\n",
    "# ff = h5py.File(mixed_phasepath+'.hdf5', 'w')\n",
    "# dd = ff.create_dataset(mixed_phasename, (0,257),maxshape=(None,257), dtype='f', chunks=True)\n",
    "# #################################\n",
    "# w=3\n",
    "# # #################################\n",
    "# for filename in a:\n",
    "#     wav_data, sr = librosa.load(os.path.join(mixed_folder,filename), sr=16000) \n",
    "#     framed_data=librosa.core.stft(wav_data, n_fft=512, hop_length=256, win_length=512, window='hann')\n",
    "#     print(framed_data.shape)\n",
    "#     abslt=np.absolute(framed_data)**2\n",
    "#     dft_signal=np.log10(abslt+1e-7*np.ones(np.shape(abslt)))\n",
    "#     for i in range(m.floor(w/2)):\n",
    "#         dft_signal=np.insert(dft_signal,0,0,axis = 1)\n",
    "#     data_phase=np.angle(framed_data)\n",
    "#     for i in range(m.floor(w/2)):\n",
    "#         data_phase=np.insert(data_phase,0,0,axis = 1)\n",
    "#     d.resize(d.shape[0]+dft_signal.shape[1], axis=0)   \n",
    "#     d[-1*dft_signal.shape[1]:] = dft_signal.T\n",
    "#     dd.resize(dd.shape[0]+data_phase.shape[1], axis=0)   \n",
    "#     dd[-1*data_phase.shape[1]:] = data_phase.T\n",
    "#     i=i+1\n",
    "####################################################\n",
    "####################################################\n",
    "import h5py\n",
    "import math as m\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from natsort import natsorted\n",
    "orig_path=os.getcwd()\n",
    "wav=[]\n",
    "clean_raw = 'clean_10h'\n",
    "l=os.listdir(os.path.normpath(os.path.join(write_path,clean_raw)))\n",
    "l=natsorted(l)\n",
    "filename1 = l[1]\n",
    "i=0\n",
    "###################################################\n",
    "w=3\n",
    "###################################################\n",
    "num_of_snrs=6\n",
    "num_of_speakers=6\n",
    "# files = os.listdir(os.path.normpath(os.path.join(Data_path,clean_raw,filename1)))\n",
    "files = os.listdir(os.path.normpath(os.path.join(write_path,clean_raw)))\n",
    "files=natsorted(files)\n",
    "# f.close()\n",
    "# ff.close()\n",
    "clean_log = 'single_dataset_log_10h_norm'\n",
    "clean_phase = 'single_dataset_phase_10h_norm'\n",
    "clean_log_path = os.path.normpath(os.path.join(write_path,clean_log))\n",
    "clean_phase_path = os.path.normpath(os.path.join(write_path,clean_phase))\n",
    "f = h5py.File(clean_log_path+'.hdf5', 'w')\n",
    "d = f.create_dataset(clean_log, (0,257),maxshape=(None,257), dtype='f', chunks=True)\n",
    "ff = h5py.File(clean_phase_path+'.hdf5', 'w')\n",
    "dd = ff.create_dataset(clean_phase, (0,257),maxshape=(None,257), dtype='f', chunks=True)\n",
    "#in this section the features for clean voices are extracted.\n",
    "for voice in files:\n",
    "    wav_data, sr = librosa.load(os.path.join(write_path,clean_raw,voice), sr=16000) \n",
    "    framed_data=librosa.core.stft(wav_data, n_fft=512, hop_length=256, win_length=512, window='hann')\n",
    "    print(framed_data.shape)\n",
    "    abslt=np.absolute(framed_data)**2\n",
    "    dft_signal=np.log10(abslt+1e-7*np.ones(np.shape(abslt)))\n",
    "    data_phase=np.angle(framed_data)\n",
    "#     for i in range(m.floor(w/2)):\n",
    "#         dft_signal=np.insert(dft_signal,0,0,axis = 1)\n",
    "#     for i in range(num_of_snrs*num_of_speakers):\n",
    "    d.resize(d.shape[0]+dft_signal.shape[1], axis=0)   \n",
    "    d[-1*dft_signal.shape[1]:] = dft_signal.T\n",
    "    dd.resize(dd.shape[0]+data_phase.shape[1], axis=0)   \n",
    "    dd[-1*data_phase.shape[1]:] = data_phase.T\n",
    "###############################################\n",
    "###############################################\n",
    "import math as m\n",
    "import numpy as np\n",
    "import h5py\n",
    "##############################################\n",
    "w = 3\n",
    "###############################################\n",
    "# mixed_logname='mixed_log_10h_norm'\n",
    "# mixed_phasename='mixed_phase_10h_norm'\n",
    "# mixed_log_path = os.path.normpath(os.path.join(write_path,mixed_logname))\n",
    "# clean_phase_path = os.path.normpath(os.path.join(write_path,mixed_phasename))\n",
    "# import h5py\n",
    "# h5f = h5py.File(mixed_log_path+'.hdf5','r')\n",
    "# ftr = h5f[mixed_logname][0:]\n",
    "# # h5f.close()\n",
    "# ftr_refrmd=[]\n",
    "# print('0')\n",
    "# for i in range(m.floor(w/2)):\n",
    "#     p=-m.floor(w/2)\n",
    "#     temp = []\n",
    "#     for j in range(w):\n",
    "#         if np.all(ftr[i]==0):\n",
    "#             break\n",
    "#         temp.extend(ftr[i+p+j])\n",
    "#     if np.any(temp!=[]):\n",
    "#         ftr_refrmd.append(temp)\n",
    "# # f.close()\n",
    "# print('1')\n",
    "# refrmd_file='ftr_refrmd_10h_norm'\n",
    "# refrmd_file_path = os.path.normpath(os.path.join(write_path,refrmd_file))\n",
    "# f = h5py.File(refrmd_file_path+'.hdf5', 'w')\n",
    "# d = f.create_dataset(refrmd_file, (0,257*w),maxshape=(None,257*w), dtype='f', chunks=True)\n",
    "# print('2')\n",
    "# for i in range(m.floor(w/2),ftr.shape[0]-m.floor(w/2)-1):\n",
    "#     k=-m.floor(w/2)\n",
    "#     temp = []\n",
    "#     for j in range(w):\n",
    "#         if np.all(ftr[i]==0):\n",
    "#             break\n",
    "#         temp.extend(ftr[i+k])\n",
    "#         k=k+1\n",
    "#     if np.any(temp!=[]):\n",
    "#         ftr_refrmd.append(temp)\n",
    "#     if len(ftr_refrmd)>50000 or i==ftr.shape[0]-m.floor(w/2)-2:\n",
    "# #         print(len(ftr_refrmd[0]))\n",
    "#         for ftr_num in range(len(ftr_refrmd)):\n",
    "#             ftr_refrmd[ftr_num] = preprocessing.scale(ftr_refrmd[ftr_num], axis=0, with_mean=True, with_std=True, copy=True)\n",
    "#         d.resize(d.shape[0]+len(ftr_refrmd), axis=0)   \n",
    "#         d[-1*len(ftr_refrmd):] = ftr_refrmd\n",
    "#         ftr_refrmd=[]\n",
    "#     if i%1000==0:\n",
    "#         print(i)\n",
    "# for i in range(ftr.shape[0]-m.floor(w/2)-1,ftr.shape[0]):\n",
    "#     p=-m.floor(w/2)\n",
    "#     temp = []\n",
    "#     for j in range(w):\n",
    "#         if np.all(ftr[i]==0):\n",
    "#             break\n",
    "#         if j>m.floor(w/2)+(ftr.shape[0]-i)-1:\n",
    "#             temp.extend(np.zeros(ftr[ftr.shape[0]-1].shape))\n",
    "#         else:\n",
    "#             temp.extend(ftr[i+p+j])\n",
    "#     if np.any(temp!=[]):\n",
    "#         ftr_refrmd.append(temp)\n",
    "# for ftr_num in range(len(ftr_refrmd)):\n",
    "#     ftr_refrmd[ftr_num] = preprocessing.scale(ftr_refrmd[ftr_num], axis=0, with_mean=True, with_std=True, copy=True)\n",
    "# d.resize(d.shape[0]+len(ftr_refrmd), axis=0)   \n",
    "# d[-1*len(ftr_refrmd):] = ftr_refrmd\n",
    "# ftr_refrmd=[]\n",
    "# f.close()\n",
    "# h5f.close()\n",
    "##############################################\n",
    "##############################################\n",
    "# import h5py\n",
    "# import numpy as np\n",
    "# h5 = h5py.File(refrmd_file, 'r')\n",
    "# d=h5[refrmd_file]\n",
    "# tot_len=d.shape[0]\n",
    "# lst=0\n",
    "# h5.close()\n",
    "# on=0\n",
    "# h5f = h5py.File(refrmd_file+'.hdf5','r')\n",
    "# for i in range(0,tot_len,1000):\n",
    "#     mixed = h5f[refrmd_file][i:i+1000]\n",
    "#     lst=lst+np.sum(mixed,axis=0)\n",
    "#     on=on+len(mixed)\n",
    "# tot_mean=lst/tot_len\n",
    "# h5f.close()\n",
    "# lst=0\n",
    "# h5f = h5py.File(refrmd_file+'.hdf5','r')\n",
    "# for i in range(0,tot_len,1000):\n",
    "#     mixed = h5f[refrmd_file][i:i+1000]\n",
    "#     lst=lst+np.sum((mixed - tot_mean)**2,axis=0)\n",
    "# lst=lst/tot_len\n",
    "# tot_std=np.sqrt(lst)\n",
    "# h5f.close()\n",
    "# f = h5py.File('ftr_scaled.hdf5', 'w')\n",
    "# dd = f.create_dataset('ftr_scaled', (0,1799),maxshape=(None,1799), dtype='f', chunks=True)\n",
    "# h5f = h5py.File('ftr_refrmd.hdf5','r')\n",
    "# for i in range(0,tot_len,1000):\n",
    "#     mixed = h5f['ftr_refrmd'][i:i+1000]\n",
    "#     scaled=(mixed-tot_mean)/tot_std\n",
    "#     dd.resize(dd.shape[0]+scaled.shape[0], axis=0)   \n",
    "#     dd[-1*scaled.shape[0]:] = scaled\n",
    "# np.savetxt('mean.txt',tot_mean)\n",
    "# np.savetxt('std.txt',tot_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
