{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "I=0\n",
    "def _parse_function(example_proto):\n",
    "    print('1')\n",
    "    features = {\"X\": tf.FixedLenFeature((3*257), tf.float32),\n",
    "              \"Y\": tf.FixedLenFeature((257), tf.float32)}\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    print(\"i was here\")\n",
    "    print('2')\n",
    "    return parsed_features[\"X\"], parsed_features[\"Y\"]\n",
    "\n",
    "def rbm_layer(n_visible, n_hidden, num_epochs, num_cases, lr, ws, bs, layer_n, len_data, directories):\n",
    "    \n",
    "    Data_path = directories[0]\n",
    "    tfrecord_folder_parent = directories[1]\n",
    "    tfrecord_folder = directories[2]\n",
    "    \n",
    "    tfrecord_path_x = os.path.normpath(os.path.join(Data_path,tfrecord_folder_parent,tfrecord_folder))\n",
    "    sorted_names_x = natsorted(os.listdir(tfrecord_path_x))\n",
    "    trainfilenames_x = []\n",
    "    for i in sorted_names_x:\n",
    "        trainfilenames_x.append(os.path.normpath(os.path.join(tfrecord_path_x,i)))\n",
    "    filenames_x = tf.placeholder(tf.string, shape=[None])\n",
    "    dataset_x = tf.data.TFRecordDataset(filenames_x)\n",
    "    dataset_x = dataset_x.map(_parse_function)  # Parse the record into tensors.\n",
    "    dataset_x = dataset_x.repeat()  # Repeat the input indefinitely.\n",
    "    dataset_x = dataset_x.batch(batch_size)\n",
    "    iterator_x = dataset_x.make_initializable_iterator()\n",
    "    \n",
    "    weightcost  = 0.0002\n",
    "    initialmomentum  = 0.5\n",
    "    finalmomentum    = 0.9\n",
    "    numcases = 128\n",
    "    W_adder  = tf.zeros((n_visible,n_hidden),dtype=tf.dtypes.float32)\n",
    "    bh_adder = tf.zeros((1,n_hidden),dtype=tf.dtypes.float32)\n",
    "    bv_adder = tf.zeros((1,n_visible),dtype=tf.dtypes.float32)\n",
    "    x  = tf.placeholder(tf.float32, [None, n_visible], name=\"x\") #The placeholder variable that holds our data\n",
    "    m  = tf.placeholder(tf.int32, name=\"m\")\n",
    "    W  = tf.Variable(tf.random_normal([n_visible, n_hidden], 0.01), name=\"W\") #The weight matrix that stores the edge weights\n",
    "    bh = tf.Variable(tf.zeros([1, n_hidden],  tf.float32, name=\"bh\")) #The bias vector for the hidden layer\n",
    "    bv = tf.Variable(tf.zeros([1, n_visible],  tf.float32, name=\"bv\")) #The bias vector for the visible layer\n",
    "\n",
    "    def sample(probs):\n",
    "        #Takes in a vector of probabilities, and returns a random vector of 0s and 1s sampled from the input vector\n",
    "        return tf.floor(probs + tf.random_uniform(tf.shape(probs), 0, 1))\n",
    "\n",
    "\n",
    "    def gibbs_sample(k):\n",
    "        #Runs a k-step gibbs chain to sample from the probability distribution of the RBM defined by W, bh, bv\n",
    "        def gibbs_step(count, k, xk):\n",
    "            #Runs a single gibbs step. The visible values are initialized to xk\n",
    "            hk = sample(tf.sigmoid(tf.matmul(xk, W) + bh)) #Propagate the visible values to sample the hidden values\n",
    "            posprods  = tf.matmul(tf.transpose(x),hk)\n",
    "            poshidacts = tf.reduce_sum(hk)\n",
    "            posvisacts = tf.reduce_sum(x,axis=0)\n",
    "            xk   = tf.sigmoid(tf.matmul(hk, tf.transpose(W)) + bv)\n",
    "            neghidprobs   = tf.sigmoid(tf.matmul(xk, W) + bh) \n",
    "            negprods  = tf.transpose(xk)*neghidprobs;\n",
    "            neghidacts = tf.reduce_sum(neghidprobs, axis=0)\n",
    "            negvisacts = tf.reduce_sum(xk, axis=0)\n",
    "            print('11')\n",
    "            print(type(posprods))\n",
    "            print(type(posvisacts))\n",
    "            print(type(negprods))\n",
    "            print(type(negvisacts))\n",
    "#             xk = sample(tf.truncated_normal((1,n_visible),tf.matmul(hk, tf.transpose(W)) + bv,1))\n",
    "            return count+1, k, xk, hk\n",
    "\n",
    "        #Run gibbs steps for k iterations\n",
    "        ct = tf.constant(0) #counter\n",
    "        print(type(ct))\n",
    "        print(type(k))\n",
    "        print(type(x))\n",
    "        [_, _, a, b]=control_flow_ops.while_loop(lambda count, num_iter, *args: count < num_iter,\n",
    "                                             gibbs_step, [ct, tf.constant(k), x], back_prop = False)\n",
    "\n",
    "        #This is not strictly necessary in this implementation, but if you want to adapt this code to use one of TensorFlow's\n",
    "        #optimizers, you need this in order to stop tensorflow from propagating gradients back through the gibbs step\n",
    "        return a,b\n",
    "\n",
    "    ### Training Update Code\n",
    "    # Now we implement the contrastive divergence algorithm. First, we get the samples of x and h from the probability distribution\n",
    "    #The sample of x\n",
    "    [x1,h1]= gibbs_sample(1) \n",
    "#     [posprod, posvisact,negprod,negvisact]= gibbs_sample(1) \n",
    "    #The sample of the hidden nodes, starting from the visible state of x\n",
    "    h = sample(tf.sigmoid(tf.matmul(x, W) + bh)) \n",
    "    #The sample of the hidden nodes, starting from the visible state of x_sample\n",
    "    h_sample = sample(tf.sigmoid(tf.matmul(x_sample, W) + bh)) \n",
    "\n",
    "    #Next, we update the values of W, bh, and bv, based on the difference between the samples that we drew and the original values\n",
    "    size_bt = tf.cast(tf.shape(x)[0], tf.float32)\n",
    "#     W_adder  = tf.multiply(lr/size_bt, tf.subtract(tf.matmul(tf.transpose(x), h), tf.matmul(tf.transpose(x_sample), h_sample)))\n",
    "#     bv_adder = tf.multiply(lr/size_bt, tf.reduce_sum(tf.subtract(x, x_sample), 0, True))\n",
    "#     bh_adder = tf.multiply(lr/size_bt, tf.reduce_sum(tf.subtract(h, h_sample), 0, True))\n",
    "    W_adder = m * W_adder+ lr*(posprod-negprod)/numcases-(weightcost*W)\n",
    "    bv_adder = m * bv_adder+ (epsilonvb/numcases)*(posvisact-negvisact)\n",
    "    bh_adder =m * bh_adder+ (epsilonhb/numcases)*(poshidact-neghidact)\n",
    "    #When we do sess.run(updt), TensorFlow will run all 3 update steps\n",
    "    updt = [W.assign_add(W_adder), bv.assign_add(bv_adder), bh.assign_add(bh_adder)]\n",
    "\n",
    "\n",
    "\n",
    "    ### Run the graph!\n",
    "    # Now it's time to start a session and run the graph! \n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        #First, we train the model\n",
    "        #initialize the variables of the model\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(iterator_x.initializer, feed_dict={filenames_x: trainfilenames_x})\n",
    "        print(iterator_x.get_next()[0])\n",
    "        #Run through all of the training data num_epochs times\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            #Train the RBM on batch_size examples at a time\n",
    "#             for X_batch in da(batch_size, layer_n, ws, bs, len_data, name, data_name):\n",
    "            Data = sess.run(iterator_x.get_next()[0])\n",
    "            for j in range(layer_n):\n",
    "                Data = np.matmul(Data,ws[j])+bs[j]\n",
    "            if epoch>5:\n",
    "                momentum=finalmomentum;\n",
    "            else:\n",
    "                momentum=initialmomentum;\n",
    "\n",
    "            feed_dict = {x: Data, m:momentum}\n",
    "            var1 = sess.run(updt, feed_dict)\n",
    "    return var1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'int'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "11\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The two structures don't have the same nested structure.\n\nFirst structure: type=list str=[<tf.Tensor 'while_6/Identity:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_1:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_2:0' shape=(?, 771) dtype=float32>]\n\nSecond structure: type=list str=[<tf.Tensor 'while_6/add_4:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_1:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Sigmoid_1:0' shape=(?, 771) dtype=float32>, <tf.Tensor 'while_6/Floor:0' shape=(?, 512) dtype=float32>]\n\nMore specifically: The two structures don't have the same number of elements. First structure: type=list str=[<tf.Tensor 'while_6/Identity:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_1:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_2:0' shape=(?, 771) dtype=float32>]. Second structure: type=list str=[<tf.Tensor 'while_6/add_4:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_1:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Sigmoid_1:0' shape=(?, 771) dtype=float32>, <tf.Tensor 'while_6/Floor:0' shape=(?, 512) dtype=float32>]\nEntire first structure:\n[., ., .]\nEntire second structure:\n[., ., ., .]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36massert_same_structure\u001b[1;34m(nest1, nest2, check_types)\u001b[0m\n\u001b[0;32m    178\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAssertSameStructure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnest2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=list str=[<tf.Tensor 'while_6/Identity:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_1:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_2:0' shape=(?, 771) dtype=float32>]\n\nSecond structure: type=list str=[<tf.Tensor 'while_6/add_4:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_1:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Sigmoid_1:0' shape=(?, 771) dtype=float32>, <tf.Tensor 'while_6/Floor:0' shape=(?, 512) dtype=float32>]\n\nMore specifically: The two structures don't have the same number of elements. First structure: type=list str=[<tf.Tensor 'while_6/Identity:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_1:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_2:0' shape=(?, 771) dtype=float32>]. Second structure: type=list str=[<tf.Tensor 'while_6/add_4:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_1:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Sigmoid_1:0' shape=(?, 771) dtype=float32>, <tf.Tensor 'while_6/Floor:0' shape=(?, 512) dtype=float32>]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ad6e89322f40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[0mhidden2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m \u001b[0mlayer1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrbm_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisible\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisible\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvisible\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdirs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[0mlayer2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrbm_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisible1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisible\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvisible\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[0mlayer3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrbm_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisible2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisible\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvisible\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-e19e38fc14dc>\u001b[0m in \u001b[0;36mrbm_layer\u001b[1;34m(n_visible, n_hidden, num_epochs, num_cases, lr, ws, bs, layer_n, len_data, directories)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m# Now we implement the contrastive divergence algorithm. First, we get the samples of x and h from the probability distribution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;31m#The sample of x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;33m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mgibbs_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;31m#     [posprod, posvisact,negprod,negvisact]= gibbs_sample(1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;31m#The sample of the hidden nodes, starting from the visible state of x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-e19e38fc14dc>\u001b[0m in \u001b[0;36mgibbs_sample\u001b[1;34m(k)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         [_, _, a, b]=control_flow_ops.while_loop(lambda count, num_iter, *args: count < num_iter,\n\u001b[1;32m---> 79\u001b[1;33m                                              gibbs_step, [ct, tf.constant(k), x], back_prop = False)\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;31m#This is not strictly necessary in this implementation, but if you want to adapt this code to use one of TensorFlow's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   3554\u001b[0m       \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3555\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[1;32m-> 3556\u001b[1;33m                                     return_same_structure)\n\u001b[0m\u001b[0;32m   3557\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3558\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[1;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[0;32m   3085\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3086\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[1;32m-> 3087\u001b[1;33m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[0;32m   3088\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3089\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[1;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   3042\u001b[0m     \u001b[1;31m# during this comparison, because inputs are typically lists and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3043\u001b[0m     \u001b[1;31m# outputs of the body are typically tuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3044\u001b[1;33m     \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3046\u001b[0m     \u001b[1;31m# Store body_result to keep track of TensorArrays returned by body\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36massert_same_structure\u001b[1;34m(nest1, nest2, check_types)\u001b[0m\n\u001b[0;32m    184\u001b[0m                   \u001b[1;34m\"Entire first structure:\\n%s\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m                   \u001b[1;34m\"Entire second structure:\\n%s\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m                   % (str(e), str1, str2))\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=list str=[<tf.Tensor 'while_6/Identity:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_1:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_2:0' shape=(?, 771) dtype=float32>]\n\nSecond structure: type=list str=[<tf.Tensor 'while_6/add_4:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_1:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Sigmoid_1:0' shape=(?, 771) dtype=float32>, <tf.Tensor 'while_6/Floor:0' shape=(?, 512) dtype=float32>]\n\nMore specifically: The two structures don't have the same number of elements. First structure: type=list str=[<tf.Tensor 'while_6/Identity:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_1:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_2:0' shape=(?, 771) dtype=float32>]. Second structure: type=list str=[<tf.Tensor 'while_6/add_4:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Identity_1:0' shape=() dtype=int32>, <tf.Tensor 'while_6/Sigmoid_1:0' shape=(?, 771) dtype=float32>, <tf.Tensor 'while_6/Floor:0' shape=(?, 512) dtype=float32>]\nEntire first structure:\n[., ., .]\nEntire second structure:\n[., ., ., .]"
     ]
    }
   ],
   "source": [
    "# import libraries.\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "# import keras\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pystoi.stoi import stoi\n",
    "import h5py\n",
    "######################\n",
    "#import libraries.\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "import os\n",
    "import librosa\n",
    "from librosa.core import stft, istft\n",
    "####import sounddevice as sd\n",
    "import time\n",
    "print('imported')\n",
    "# #######################\n",
    "Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "# Data_path = os.getcwd()\n",
    "tfrecord_folder_parent = 'tfrecord_files'\n",
    "tfrecord_folder = 'tfrecord_files_10h_norm'\n",
    "tfrecord_val_folder = 'validation_10h_norm'\n",
    "ckpt_folder = '3'\n",
    "dirs = [Data_path, tfrecord_folder_parent, tfrecord_folder]\n",
    " \n",
    "# len_data = (684108, 257)\n",
    "len_data = (100000, 257)\n",
    "val_len = (97278,257)\n",
    "w=3\n",
    "#######################\n",
    "#define reconstruct function to reconstruct sound from framed signal.\n",
    "def reconstruct(wave,angle):\n",
    "    recon = np.sqrt(np.power(10, wave))\n",
    "    recon1 = recon*np.cos(angle)+recon*np.sin(angle)*1j\n",
    "    recon = librosa.core.istft((recon1.T), hop_length=200, win_length=500, window='hann')\n",
    "    return recon\n",
    "#######################\n",
    "I=0\n",
    "global batch_size\n",
    "batch_size = 128\n",
    "# epochs_num=50\n",
    "global datalen\n",
    "datalen=len_data[0]\n",
    "\n",
    "h = [512,512]\n",
    "seed = 7\n",
    "rate1 = 0.1\n",
    "rate2 = 0.2\n",
    "from tensorflow.keras.layers import Activation\n",
    "# from keras.layers import Activation\n",
    "np.random.seed(seed)\n",
    "model = Sequential()\n",
    "act1 = layers.LeakyReLU(alpha=0.1)\n",
    "model.add(layers.Dropout(rate1, noise_shape=None, seed=None))\n",
    "# ,kernel_regularizer=regularizers.l2(0.001)\n",
    "model.add(Dense(h[0], input_dim = w*len_data[1]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(act1)\n",
    "# model.add(Activation('sigmoid'))\n",
    "act2=layers.LeakyReLU(alpha=0.1)\n",
    "model.add(layers.Dropout(rate2, noise_shape=None, seed=None))\n",
    "model.add(Dense(h[1]))\n",
    "model.add(act2)\n",
    "# act3=layers.LeakyReLU(alpha=0.1)\n",
    "# # model.add(layers.Dropout(rate, noise_shape=None, seed=None))\n",
    "# model.add(Dense(h[2]))\n",
    "# model.add(act3)\n",
    "act=layers.LeakyReLU(alpha=0.01)\n",
    "model.add(Dense(len_data[1]))\n",
    "#############################################\n",
    "import os\n",
    "from natsort import natsorted\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    features = {\"X\": tf.FixedLenFeature((3*257), tf.float32),\n",
    "              \"Y\": tf.FixedLenFeature((257), tf.float32)}\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    return parsed_features[\"X\"], parsed_features[\"Y\"]\n",
    "\n",
    "tfrecord_path = os.path.normpath(os.path.join(Data_path,tfrecord_folder_parent,tfrecord_folder))\n",
    "sorted_names = natsorted(os.listdir(tfrecord_path))\n",
    "trainfilenames = []\n",
    "for i in sorted_names:\n",
    "    trainfilenames.append(os.path.normpath(os.path.join(tfrecord_path,i)))\n",
    "filenames = tf.placeholder(tf.string, shape=[None])\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "dataset = dataset.map(_parse_function)  # Parse the record into tensors.\n",
    "dataset = dataset.repeat()  # Repeat the input indefinitely.\n",
    "dataset = dataset.batch(batch_size)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "# orig_path = os.getcwd()\n",
    "tfrecord_path_x = os.path.normpath(os.path.join(Data_path,tfrecord_folder_parent,tfrecord_folder))\n",
    "sorted_names_x = natsorted(os.listdir(tfrecord_path_x))\n",
    "trainfilenames_x = []\n",
    "for i in sorted_names_x:\n",
    "    trainfilenames_x.append(os.path.normpath(os.path.join(tfrecord_path,i)))\n",
    "filenames_x = tf.placeholder(tf.string, shape=[None])\n",
    "dataset_x = tf.data.TFRecordDataset(filenames_x)\n",
    "dataset_x = dataset_x.map(_parse_function)  # Parse the record into tensors.\n",
    "dataset_x = dataset_x.repeat()  # Repeat the input indefinitely.\n",
    "dataset_x = dataset_x.batch(batch_size)\n",
    "iterator_x = dataset_x.make_initializable_iterator()\n",
    "\n",
    "########################\n",
    "visible = w*len_data[1]\n",
    "hidden = h[0]\n",
    "visible1 = h[0]\n",
    "hidden1 = h[1]\n",
    "visible2 = h[1]\n",
    "hidden2 = len_data[1]\n",
    "\n",
    "layer1 = rbm_layer(visible, hidden, 50, batch_size, 0.01, [np.eye(visible)], [np.zeros((1,visible))], 1, len_data[0],dirs)\n",
    "layer2 = rbm_layer(visible1, hidden1, 50, batch_size, 0.01, [np.eye(visible),layer1[0]], [np.zeros((1,visible)),layer1[2]], 2, len_data[0], dirs)\n",
    "layer3 = rbm_layer(visible2, hidden2, 50, batch_size, 0.01, [np.eye(visible),layer1[0],layer2[0]], [np.zeros((1,visible)),layer1[2],layer2[2]], 3, len_data[0], dirs)\n",
    "\n",
    "###############################\n",
    "\n",
    "# tfrecord_path_val = os.path.normpath(os.path.join(Data_path,tfrecord_folder_parent,tfrecord_val_folder))\n",
    "# sorted_names_val = natsorted(os.listdir(tfrecord_path_val))\n",
    "# trainfilenames_val = []\n",
    "# for i in sorted_names_val:\n",
    "#     trainfilenames_val.append(os.path.normpath(os.path.join(tfrecord_path_val,i)))\n",
    "# filenames_val = tf.placeholder(tf.string, shape=[None])\n",
    "# dataset_val = tf.data.TFRecordDataset(filenames_val)\n",
    "# dataset_val = dataset_val.map(_parse_function)  # Parse the record into tensors.\n",
    "# dataset_val = dataset_val.repeat()  # Repeat the input indefinitely.\n",
    "# dataset_val = dataset_val.batch(128)\n",
    "# iterator_val = dataset_val.make_initializable_iterator()\n",
    "\n",
    "# epochs_num = 50\n",
    "# steps = len_data[0] // batch_size\n",
    "# val_steps = val_len[0] // batch_size\n",
    "# # You can feed the initializer with the appropriate filenames for the current\n",
    "# # phase of execution, e.g. training vs. validation.\n",
    "# # next_elem = iterator_val.get_next()\n",
    "# # Initialize `iterator` with training data.\n",
    "\n",
    "# if not os.path.exists(os.path.join(Data_path,\"checkpoints\",ckpt_folder)):\n",
    "#     os.makedirs(os.path.join(Data_path,\"checkpoints\",ckpt_folder))\n",
    "\n",
    "# print(datetime.datetime.now())\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     sess.run(iterator.initializer, feed_dict={filenames: trainfilenames})\n",
    "#     sess.run(iterator_val.initializer, feed_dict={filenames_val: trainfilenames_val})\n",
    "#     print(\"initialized\")\n",
    "#     checkpoint_path = os.path.normpath(os.path.join(Data_path,\"checkpoints\",ckpt_folder,\"weights.{epoch:02d}.hdf5\"))\n",
    "#     checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "#     cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#         checkpoint_path, verbose=1, save_best_only=True, save_weights_only=True)\n",
    "#         # Save weights, every 5-epochs.\n",
    "# #         period=1)\n",
    "#     early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)\n",
    "#     opt = tf.keras.optimizers.Adamax()\n",
    "# #     opt = tf.train.AdamOptimizer()\n",
    "# #     opt = tf.keras.optimizers.SGD()\n",
    "#     model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "#     history = model.fit( iterator, steps_per_epoch=steps,epochs=epochs_num, callbacks = [cp_callback,early_stop], verbose=1,validation_data=iterator_val,validation_steps=val_steps)\n",
    "# #     model.save(os.path.normpath(os.path.join(Data_path, 'models', \"model_3h_dataset.h5\")))\n",
    "# #     tf.keras.models.save_model(model, os.path.normpath(os.path.join(Data_path, 'models', \"model_3h_dataset.h5\")))\n",
    "# #     model.save_weights(os.path.normpath(os.path.join(Data_path, 'models', \"model_3h_dataset.h5\")))\n",
    "#     model_json = model.to_json()\n",
    "#     with open(os.path.normpath(os.path.join(Data_path, 'models', \"model_3.json\")), \"w\") as json_file:\n",
    "#         json_file.write(model_json)\n",
    "#     # # serialize weights to HDF5\n",
    "#     model.save_weights(os.path.normpath(os.path.join(Data_path, 'models', \"model_3.h5\")))\n",
    "#     print(\"Saved model to disk\")\n",
    "    \n",
    "# print(datetime.datetime.now())\n",
    "# %matplotlib inline\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train'], loc='upper left')\n",
    "# plt.show()\n",
    "# plt.savefig(os.path.normpath(os.path.join(Data_path,'images',ckpt_folder+'.png')))\n",
    "# # model_json = model.to_json()\n",
    "# # with open(\"model_10h_dataset.json\", \"w\") as json_file:\n",
    "# #     json_file.write(model_json)\n",
    "# # model.save_weights(\"model_10h_dataset.h5\")\n",
    "# # print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff/10hdata'\n",
    "mixed_folder = os.path.normpath(os.path.join(write_path,'ftr_refrmd_10h'))\n",
    "h5f = h5py.File(mixed_folder+'.hdf5','r')\n",
    "ftr = h5f['ftr_refrmd_10h_norm'][0:126]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = np.matmul(ftr,layer1[0])+layer1[2]\n",
    "hidden2 = np.matmul(hidden1,layer2[0])+layer2[2]\n",
    "hidden3 = np.matmul(hidden2,layer3[0])+layer3[2]\n",
    "hidden3_b = np.matmul(hidden3,layer3[0].T)+layer3[1]\n",
    "hidden2_b = np.matmul(hidden3_b,layer2[0].T)+layer2[1]\n",
    "hidden1_b = np.matmul(hidden2_b,layer1[0].T)+layer1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.68445486,  1.7240543 ,  1.6643912 , ...,  0.45980495,\n",
       "        -0.39418986, -0.22753727],\n",
       "       [ 0.5786126 , -1.3953351 , -0.31091535, ...,  0.818933  ,\n",
       "        -1.2809952 , -0.50011426],\n",
       "       [ 0.05083557, -2.1963139 , -1.0158075 , ..., -0.3168898 ,\n",
       "        -0.5269073 ,  0.44966087],\n",
       "       ...,\n",
       "       [ 0.634739  , -0.4692638 , -0.01245244, ..., -0.3467159 ,\n",
       "         0.69092953, -0.03271168],\n",
       "       [-1.1067898 ,  0.43947145, -0.93950135, ..., -1.301825  ,\n",
       "        -2.0738528 , -0.8969364 ],\n",
       "       [-0.70347303,  0.7096946 , -2.2489529 , ...,  1.1123182 ,\n",
       "         1.1656525 , -1.1219527 ]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ..., -4.9426355 ,\n",
       "        -4.978707  , -6.258066  ],\n",
       "       [ 0.8652955 ,  0.4874023 , -0.74453855, ..., -5.1649346 ,\n",
       "        -4.9139147 , -4.619758  ],\n",
       "       [ 0.61080295,  0.6883045 , -0.34954664, ..., -5.2531357 ,\n",
       "        -5.9172816 , -5.9053864 ],\n",
       "       ...,\n",
       "       [-7.        , -7.        , -7.        , ..., -7.        ,\n",
       "        -7.        , -7.        ],\n",
       "       [-7.        , -7.        , -7.        , ..., -7.        ,\n",
       "        -7.        , -7.        ],\n",
       "       [-7.        , -7.        , -7.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.9518034e+18,  6.7135300e+18,  4.0281955e+18, ...,\n",
       "        -3.0091000e+18, -9.3845758e+18, -2.4322354e+18],\n",
       "       [ 8.0057635e+18,  1.0854019e+19,  6.5125393e+18, ...,\n",
       "        -4.8649316e+18, -1.5172409e+19, -3.9322871e+18],\n",
       "       [ 8.8405996e+18,  1.1985860e+19,  7.1916576e+18, ...,\n",
       "        -5.3722353e+18, -1.6754568e+19, -4.3423436e+18],\n",
       "       ...,\n",
       "       [ 5.9835995e+18,  8.1124145e+18,  4.8675435e+18, ...,\n",
       "        -3.6361023e+18, -1.1340024e+19, -2.9390366e+18],\n",
       "       [ 5.9835995e+18,  8.1124145e+18,  4.8675435e+18, ...,\n",
       "        -3.6361023e+18, -1.1340024e+19, -2.9390366e+18],\n",
       "       [ 4.5460279e+18,  6.1633872e+18,  3.6981051e+18, ...,\n",
       "        -2.7625221e+18, -8.6155549e+18, -2.2329248e+18]], dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.constant([1,2,3])\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    label_numpy = a.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(771,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py \n",
    "import tensorflow as tf\n",
    "hh = h5py.File('ftr_refrmd_10h.hdf5', 'r')\n",
    "d=hh['ftr_refrmd_10h'][0]\n",
    "len_data=d.shape\n",
    "hh.close()\n",
    "len_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((?, 257), (?,)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
