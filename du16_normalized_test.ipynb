{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from pystoi.stoi import stoi\n",
    "import mir_eval #https://github.com/craffel/mir_eval\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "# import keras\n",
    "from scipy.io import wavfile\n",
    "from pypesq import pesq #https://github.com/vBaiCai/python-pesq\n",
    "import vqmetrics\n",
    "from natsort import natsorted\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define reconstruct function to reconstruct sound from framed signal.\n",
    "def reconstruct(wave,angle):\n",
    "    recon = np.sqrt(np.power(10, wave))\n",
    "    recon1 = recon*np.cos(angle)+recon*np.sin(angle)*1j\n",
    "    recon = librosa.core.istft((recon1.T), hop_length=256, win_length=512, window='hann')\n",
    "    return recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(os.path.normpath(os.path.join(Data_path,'partly_trained.h5')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from keras.models import load_model\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras import layers\n",
    "\n",
    "# w=3\n",
    "# h = [1024,512]\n",
    "# len_data = (684108, 257)\n",
    "# model = Sequential()\n",
    "# act=layers.LeakyReLU(alpha=0.1)\n",
    "# model.add(Dense(h[0], input_dim = w*len_data[1]))\n",
    "# # model.add(BatchNormalization())\n",
    "# model.add(act)\n",
    "# act=layers.LeakyReLU(alpha=0.1)\n",
    "# model.add(Dense(h[1]))\n",
    "# model.add(act)\n",
    "# act=layers.LeakyReLU(alpha=0.1)\n",
    "# model.add(Dense(len_data[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = os.path.normpath(os.path.join(Data_path,'checkpoints', 'normal','cp-0050.ckpt'))\n",
    "# model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "# # json_file = open(os.path.normpath(os.path.join(Data_path,'models','model_3h_dataset.json')), 'r')\n",
    "# model_path = os.path.normpath(os.path.join(Data_path,'models','model_3h_dataset.json'))\n",
    "# # loaded_model_json = json_file.read()\n",
    "# # json_file.close()\n",
    "# # loaded_model = model_from_json(loaded_model_json)\n",
    "# loaded_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "json_file = open(os.path.normpath(os.path.join(Data_path,'models','model_3h_dataset_3.json')), 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(os.path.normpath(os.path.join(Data_path,'models','model_3h_dataset_3.h5')))\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "(122, 771)\n",
      "0.9999999999999999\n",
      "(111, 771)\n",
      "1.0\n",
      "(114, 771)\n",
      "1.0\n",
      "(101, 771)\n",
      "0.9999999999999999\n",
      "(116, 771)\n",
      "1.0\n",
      "(116, 771)\n",
      "0.9999999999999999\n",
      "(116, 771)\n",
      "1.0\n",
      "(114, 771)\n",
      "1.0\n",
      "(121, 771)\n",
      "1.0\n",
      "(114, 771)\n",
      "1.0\n",
      "(121, 771)\n",
      "1.0\n",
      "(111, 771)\n",
      "1.0\n",
      "(108, 771)\n",
      "1.0\n",
      "(120, 771)\n",
      "1.0\n",
      "(116, 771)\n",
      "1.0\n",
      "(110, 771)\n",
      "1.0\n",
      "(111, 771)\n",
      "1.0\n",
      "(112, 771)\n",
      "1.0\n",
      "(118, 771)\n",
      "1.0\n",
      "(110, 771)\n",
      "1.0\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "(122, 771)\n",
      "0.9999999999999999\n",
      "(111, 771)\n",
      "1.0\n",
      "(114, 771)\n",
      "1.0\n",
      "(101, 771)\n",
      "1.0\n",
      "(116, 771)\n",
      "1.0\n",
      "(116, 771)\n",
      "0.9999999999999999\n",
      "(116, 771)\n",
      "1.0\n",
      "(114, 771)\n",
      "1.0\n",
      "(121, 771)\n",
      "1.0\n",
      "(114, 771)\n",
      "1.0\n",
      "(121, 771)\n",
      "0.9999999999999999\n",
      "(111, 771)\n",
      "1.0000000000000002\n",
      "(108, 771)\n",
      "1.0\n",
      "(120, 771)\n",
      "0.9999999999999999\n",
      "(116, 771)\n",
      "1.0\n",
      "(110, 771)\n",
      "1.0\n",
      "(111, 771)\n",
      "1.0\n",
      "(112, 771)\n",
      "1.0\n",
      "(118, 771)\n",
      "1.0\n",
      "(110, 771)\n",
      "0.9999999999999999\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "(122, 771)\n",
      "1.0\n",
      "(111, 771)\n",
      "0.9999999999999999\n",
      "(114, 771)\n",
      "1.0\n",
      "(101, 771)\n",
      "1.0\n",
      "(116, 771)\n",
      "1.0\n",
      "(116, 771)\n",
      "1.0\n",
      "(116, 771)\n",
      "1.0\n",
      "(114, 771)\n",
      "1.0\n",
      "(121, 771)\n",
      "1.0\n",
      "(114, 771)\n",
      "1.0\n",
      "(121, 771)\n",
      "1.0\n",
      "(111, 771)\n",
      "1.0\n",
      "(108, 771)\n",
      "1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5d29459170b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mX_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_std\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_log\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mX_phase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mData_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'test_phase2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename22\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mData_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'test_log'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'clean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename33\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mframed_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwin_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hann'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[1;31m# converting the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[1;34m(chunk_size)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \"\"\"\n\u001b[0;32m   1006\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirst_line\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m             \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stoi_eval=[]\n",
    "sdr=[]\n",
    "stoi_mixed=[]\n",
    "sdr_mixed=[]\n",
    "mean_sdr=[]\n",
    "mean_sdr_mixed=[]\n",
    "mean_stoi=[]\n",
    "mean_stoi_mixed=[]\n",
    "# orig_path=os.getcwd()\n",
    "Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "w = 3\n",
    "inputs = os.listdir(os.path.join(Data_path,'ftr_refrmd_test'))\n",
    "inputs = natsorted(inputs)\n",
    "mixed = os.listdir(os.path.join(Data_path,'test_log2'))\n",
    "mixed = natsorted(mixed)\n",
    "clean1 = os.listdir(os.path.join(Data_path,'test_log','clean'))\n",
    "clean1 = natsorted(clean1)\n",
    "clean = clean1.copy()\n",
    "j=0\n",
    "parent = 'results'\n",
    "foldername='results_3h_3'\n",
    "print(len(clean))\n",
    "for i in range(len(inputs)-1):\n",
    "    clean=np.concatenate((clean,clean1),axis=0)\n",
    "phase = os.listdir(os.path.join(Data_path,'test_phase2'))\n",
    "phase = natsorted(phase)\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername)):\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername))\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername,'pesq')):\n",
    "#     print('creating pesq')\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername,'pesq'))\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername,'sdr')):\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername,'sdr'))\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername,'stoi')):\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername,'stoi'))\n",
    "for filename1,filename2,filename4 in zip(inputs,phase,mixed):\n",
    "    print(filename1)\n",
    "    print(filename2)\n",
    "    print(filename4)\n",
    "    a = os.listdir(os.path.join(Data_path,'ftr_refrmd_test',filename1))\n",
    "    b = os.listdir(os.path.join(Data_path,'test_phase2',filename2))\n",
    "    print('blah')\n",
    "    c = os.listdir(os.path.join(Data_path,'test_log2',filename4))\n",
    "    stoi_eval=[]\n",
    "    pesq_eval=[]\n",
    "    sdr=[]\n",
    "    stoi_mixed=[]\n",
    "    sdr_mixed=[]\n",
    "    if not os.path.exists(os.path.join(Data_path,parent,foldername,filename1)):\n",
    "        os.mkdir(os.path.join(Data_path,parent,foldername,filename1))\n",
    "    for filename11,filename22,filename33,filename44 in zip(a,b,clean,c):\n",
    "        X_log=np.loadtxt(os.path.join(Data_path,'ftr_refrmd_test',filename1,filename11),delimiter=',')\n",
    "        print(X_log.shape)\n",
    "        X_log = preprocessing.scale(X_log, axis=1, with_mean=True, with_std=True, copy=True)\n",
    "        print(np.std(X_log))\n",
    "        X_phase=np.loadtxt(os.path.join(Data_path,'test_phase2',filename2,filename22),delimiter=',')\n",
    "        target = np.loadtxt(os.path.join(Data_path,'test_log','clean',filename33),delimiter=',')\n",
    "        framed_data=librosa.core.stft(target, n_fft=512, hop_length=256, win_length=512, window='hann')\n",
    "        abslt=np.absolute(framed_data)**2\n",
    "        dft_signal=np.log10(abslt+1e-7*np.ones(np.shape(abslt)))\n",
    "        mixed_files=np.loadtxt(os.path.join(Data_path,'test_log2',filename4,filename44),delimiter=',')\n",
    "        prediction = loaded_model.predict(X_log)\n",
    "        recon_out = reconstruct(prediction, X_phase)\n",
    "        recon_mixed = reconstruct(mixed_files, X_phase)\n",
    "        recon_clean = reconstruct(dft_signal.T, X_phase)\n",
    "        wavfile.write(os.path.join(Data_path,parent,foldername,filename1)+'\\\\'+filename11.replace('.txt','')+'.wav',16000,recon_out)\n",
    "        target = target[0:len(recon_out)]\n",
    "        #target = np.reshape(target,(1,len(recon_out)))\n",
    "        #recon_out=np.reshape(recon_out,(1,len(recon_out)))\n",
    "#         pesq_eval.append(get_pesq(target, recon_out,16000))\n",
    "        sdr.append(mir_eval.separation.bss_eval_sources(target, recon_out, compute_permutation=False)[0][0])\n",
    "        stoi_eval.append(stoi(target, recon_out, 16000, extended=False))\n",
    "        sdr_mixed.append(mir_eval.separation.bss_eval_sources(target, recon_mixed, compute_permutation=False)[0][0])\n",
    "        stoi_mixed.append(stoi(target, recon_mixed, 16000, extended=False))\n",
    "    mean_stoi.append(np.mean(stoi_eval))\n",
    "    mean_stoi_mixed.append(np.mean(stoi_mixed))\n",
    "    mean_sdr.append(np.mean(sdr))\n",
    "    mean_sdr_mixed.append(np.mean(sdr_mixed))\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername,'sdr')+'\\\\'+'predictedsdr.txt',mean_sdr, fmt='%1.4f')\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername,'sdr')+'\\\\'+'mixedsdr.txt',mean_sdr_mixed, fmt='%1.4f')\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername,'stoi')+'\\\\'+'predictedstoi.txt',mean_stoi, fmt='%1.4f')\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername,'stoi')+'\\\\'+'mixedstoi.txt',mean_stoi_mixed, fmt='%1.4f')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6693284360807059,\n",
       " 1.8824042421698857,\n",
       " 2.8409742174070693,\n",
       " -0.7172409709172369,\n",
       " -2.3017126997260933,\n",
       " -4.025477839106158]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3102860913406525,\n",
       " 3.2391316120756075,\n",
       " 6.200104618041733,\n",
       " -2.5593159169272797,\n",
       " -5.322344893230758,\n",
       " -7.901038729183284]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sdr_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pesq(reference, degraded, sample_rate=None, program='pesq'):\n",
    "    \"\"\" Return PESQ quality estimation (two values: PESQ MOS and MOS LQO) based\n",
    "    on reference and degraded speech samples comparison.\n",
    "    Sample rate must be 8000 or 16000 (or can be defined reading reference file\n",
    "    header).\n",
    "    PESQ utility must be installed.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(reference) or not os.path.isfile(degraded):\n",
    "        raise ValueError('reference or degraded file does not exist')\n",
    "    if not sample_rate:\n",
    "        import wave\n",
    "        w = wave.open(reference, 'r')\n",
    "        sample_rate = w.getframerate()\n",
    "        w.close()\n",
    "    if sample_rate not in (8000, 16000):\n",
    "        raise ValueError('sample rate must be 8000 or 16000')\n",
    "    import subprocess\n",
    "    args = [ program, '+%d' % sample_rate, reference, degraded  ]\n",
    "    pipe = subprocess.Popen(args, stdout=subprocess.PIPE)\n",
    "    out, _ = pipe.communicate()\n",
    "    last_line = out.split('\\n')[-2]\n",
    "    if not last_line.startswith('P.862 Prediction'):\n",
    "        raise ValueError(last_line)\n",
    "    return tuple(map(float, last_line.split()[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isfile('down_mixed501_1_16bit.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.reshape(target,(1,target.shape[0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sdr_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_stoi_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "sd.play(recon_out,16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "loaded_model.get_weights()[7].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framed_data=librosa.core.stft(target, n_fft=512, hop_length=256, win_length=512, window='hann')\n",
    "abslt=np.absolute(framed_data)**2\n",
    "dft_signal=np.log10(abslt+1e-7*np.ones(np.shape(abslt)))\n",
    "reconstruct(dft_signal.T,X_phase).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "# recon = reconstruct(X_log[:,0:257], X_phase)\n",
    "samplerate=16000\n",
    "sd.play(recon_clean, samplerate)\n",
    "#sd.play(target.T, samplerate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_mixed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_path=os.getcwd()\n",
    "w = 7\n",
    "inputs = os.listdir(os.path.join(orig_path,'ftr_refrmd_test'))\n",
    "inputs = natsorted(inputs)\n",
    "clean1 = os.listdir(os.path.join(orig_path,'test_log','clean'))\n",
    "clean1 = natsorted(clean1)\n",
    "clean = clean1.copy()\n",
    "print(len(clean))\n",
    "for i in range(len(inputs)-1):\n",
    "    clean=np.concatenate((clean,clean1),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_log=np.loadtxt('test_log\\\\'+'3'+'\\\\'+'t2_bwbn2s_m2_brif5p'+'.txt', delimiter=',')\n",
    "X_phase=np.loadtxt('test_phase\\\\'+'3'+'\\\\'+'t2_bwbn2s_m2_brif5p'+'.txt', delimiter=',')\n",
    "recon = reconstruct(X_log, X_phase)\n",
    "sdr=mir_eval.separation.bss_eval_sources(recon, recon, compute_permutation=True)[0][0]\n",
    "sir=mir_eval.separation.bss_eval_sources(recon, recon, compute_permutation=True)[1][0]\n",
    "sar=mir_eval.separation.bss_eval_sources(recon, recon, compute_permutation=True)[2][0]\n",
    "stoi_ev=stoi(recon, recon, 16000, extended=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pesq_ev=vqmetrics.pesq('t2_bwigzs_m2_sbit3p.wav', 't2_bwigzs_m2_sbit3p.wav',16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pesq_ev=pesq(recon, recon, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "process = subprocess.Popen(command, stdout=tempFile, shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
