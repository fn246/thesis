{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################i tested rbm from the guy in github, this code has implemented the exact pper from hinton.\n",
    "\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "I=0\n",
    "def _parse_function(example_proto):\n",
    "    features = {\"X\": tf.FixedLenFeature((257), tf.float32),\n",
    "              \"Y\": tf.FixedLenFeature((257), tf.float32)}\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    return parsed_features[\"X\"], parsed_features[\"Y\"]\n",
    "\n",
    "def rbm_layer(n_visible, n_hidden, num_epochs, num_cases, lr, ws, bs, layer_n, len_data, directories):\n",
    "    \n",
    "    Data_path = directories[0]\n",
    "    tfrecord_folder_parent = directories[1]\n",
    "    tfrecord_folder = directories[2]\n",
    "    \n",
    "    tfrecord_path_x = os.path.normpath(os.path.join(Data_path,tfrecord_folder_parent,tfrecord_folder))\n",
    "    sorted_names_x = natsorted(os.listdir(tfrecord_path_x))\n",
    "    trainfilenames_x = []\n",
    "    for i in sorted_names_x:\n",
    "        trainfilenames_x.append(os.path.normpath(os.path.join(tfrecord_path_x,i)))\n",
    "    filenames_x = tf.placeholder(tf.string, shape=[None])\n",
    "    dataset_x = tf.data.TFRecordDataset(filenames_x)\n",
    "    dataset_x = dataset_x.map(_parse_function)  # Parse the record into tensors.\n",
    "    dataset_x = dataset_x.repeat()  # Repeat the input indefinitely.\n",
    "    dataset_x = dataset_x.batch(batch_size)\n",
    "    iterator_x = dataset_x.make_initializable_iterator()\n",
    "\n",
    "    x  = tf.placeholder(tf.float32, [None, n_visible], name=\"x\") #The placeholder variable that holds our data\n",
    "    W  = tf.Variable(tf.random_normal([n_visible, n_hidden], 0.01), name=\"W\") #The weight matrix that stores the edge weights\n",
    "    bh = tf.Variable(tf.zeros([1, n_hidden],  tf.float32, name=\"bh\")) #The bias vector for the hidden layer\n",
    "    bv = tf.Variable(tf.zeros([1, n_visible],  tf.float32, name=\"bv\")) #The bias vector for the visible layer\n",
    "\n",
    "    def sample(probs):\n",
    "        #Takes in a vector of probabilities, and returns a random vector of 0s and 1s sampled from the input vector\n",
    "        return tf.floor(probs + tf.random_uniform(tf.shape(probs), 0, 1))\n",
    "\n",
    "\n",
    "    def gibbs_sample(k):\n",
    "        #Runs a k-step gibbs chain to sample from the probability distribution of the RBM defined by W, bh, bv\n",
    "        def gibbs_step(count, k, xk):\n",
    "            #Runs a single gibbs step. The visible values are initialized to xk\n",
    "            hk = sample(tf.sigmoid(tf.matmul(xk, W) + bh)) #Propagate the visible values to sample the hidden values\n",
    "#             xk   = tf.sigmoid(tf.matmul(hk, tf.transpose(W)) + bv)\n",
    "            xk = sample(tf.truncated_normal((1,n_visible),tf.matmul(hk, tf.transpose(W)) + bv,1))\n",
    "            return count+1, k, xk\n",
    "        print('2')\n",
    "        ct = tf.constant(0) #counter\n",
    "        #Run gibbs steps for k iterations\n",
    "        [_, _, x_sample]=control_flow_ops.while_loop(lambda count, num_iter, *args: count < num_iter,\n",
    "                                             gibbs_step, [ct, tf.constant(k), x], back_prop = False)\n",
    "        print('3')\n",
    "        #This is not strictly necessary in this implementation, but if you want to adapt this code to use one of TensorFlow's\n",
    "        #optimizers, you need this in order to stop tensorflow from propagating gradients back through the gibbs step\n",
    "        x_sample = tf.stop_gradient(x_sample) \n",
    "        print('4')\n",
    "        return x_sample\n",
    "\n",
    "    ### Training Update Code\n",
    "    # Now we implement the contrastive divergence algorithm. First, we get the samples of x and h from the probability distribution\n",
    "    #The sample of x\n",
    "    print('1')\n",
    "    x_sample = gibbs_sample(1) \n",
    "    #The sample of the hidden nodes, starting from the visible state of x\n",
    "    h = sample(tf.sigmoid(tf.matmul(x, W) + bh)) \n",
    "    #The sample of the hidden nodes, starting from the visible state of x_sample\n",
    "    h_sample = sample(tf.sigmoid(tf.matmul(x_sample, W) + bh)) \n",
    "\n",
    "    #Next, we update the values of W, bh, and bv, based on the difference between the samples that we drew and the original values\n",
    "#     size_bt = tf.cast(tf.shape(x)[0], tf.float32)\n",
    "    W_adder  = tf.multiply(lr, tf.subtract(tf.matmul(tf.transpose(x), h), tf.matmul(tf.transpose(x_sample), h_sample)))\n",
    "    bv_adder = tf.multiply(lr, tf.reduce_sum(tf.subtract(x, x_sample), 0, True))\n",
    "    bh_adder = tf.multiply(lr, tf.reduce_sum(tf.subtract(h, h_sample), 0, True))\n",
    "    #When we do sess.run(updt), TensorFlow will run all 3 update steps\n",
    "    updt = [W.assign_add(W_adder), bv.assign_add(bv_adder), bh.assign_add(bh_adder)]\n",
    "\n",
    "\n",
    "\n",
    "    ### Run the graph!\n",
    "    # Now it's time to start a session and run the graph! \n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        #First, we train the model\n",
    "        #initialize the variables of the model\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(iterator_x.initializer, feed_dict={filenames_x: trainfilenames_x})\n",
    "#         print(iterator_x.get_next()[0])\n",
    "        #Run through all of the training data num_epochs times\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            #Train the RBM on batch_size examples at a time\n",
    "#             for X_batch in da(batch_size, layer_n, ws, bs, len_data, name, data_name):\n",
    "            Data = sess.run(iterator_x.get_next()[0])\n",
    "            for j in range(layer_n):\n",
    "#                 print(ws[j].shape)\n",
    "#                 print(bs[j].shape)\n",
    "#                 print(type(Data))\n",
    "                Data = np.matmul(Data,ws[j])+bs[j]\n",
    "            feed_dict = {x: Data}\n",
    "            var1 = sess.run(updt, feed_dict)\n",
    "#             print(bh.eval())\n",
    "    return var1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 34.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# import libraries.\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "# import keras\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pystoi.stoi import stoi\n",
    "import h5py\n",
    "######################\n",
    "#import libraries.\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "import os\n",
    "import librosa\n",
    "from librosa.core import stft, istft\n",
    "####import sounddevice as sd\n",
    "import time\n",
    "print('imported')\n",
    "# #######################\n",
    "Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "# Data_path = os.getcwd()\n",
    "tfrecord_folder_parent = 'tfrecord_files'\n",
    "tfrecord_folder = 'mixed_10h_norm2'\n",
    "tfrecord_val_folder = 'validation_10h'\n",
    "ckpt_folder = '3'\n",
    "dirs = [Data_path, tfrecord_folder_parent, tfrecord_folder]\n",
    " \n",
    "# len_data = (684108, 257)\n",
    "len_data = (100000, 257)\n",
    "val_len = (97278,257)\n",
    "w=1\n",
    "#######################\n",
    "#define reconstruct function to reconstruct sound from framed signal.\n",
    "def reconstruct(wave,angle):\n",
    "    recon = np.sqrt(np.power(10, wave))\n",
    "    recon1 = recon*np.cos(angle)+recon*np.sin(angle)*1j\n",
    "    recon = librosa.core.istft((recon1.T), hop_length=200, win_length=500, window='hann')\n",
    "    return recon\n",
    "#######################\n",
    "I=0\n",
    "global batch_size\n",
    "batch_size = 128\n",
    "# epochs_num=50\n",
    "global datalen\n",
    "datalen=len_data[0]\n",
    "\n",
    "h = [512,512]\n",
    "seed = 7\n",
    "rate1 = 0.1\n",
    "rate2 = 0.2\n",
    "from tensorflow.keras.layers import Activation\n",
    "# from keras.layers import Activation\n",
    "np.random.seed(seed)\n",
    "model = Sequential()\n",
    "act1 = layers.LeakyReLU(alpha=0.1)\n",
    "model.add(layers.Dropout(rate1, noise_shape=None, seed=None))\n",
    "# ,kernel_regularizer=regularizers.l2(0.001)\n",
    "model.add(Dense(h[0], input_dim = w*len_data[1]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(act1)\n",
    "# model.add(Activation('sigmoid'))\n",
    "act2=layers.LeakyReLU(alpha=0.1)\n",
    "model.add(layers.Dropout(rate2, noise_shape=None, seed=None))\n",
    "model.add(Dense(h[1]))\n",
    "model.add(act2)\n",
    "# act3=layers.LeakyReLU(alpha=0.1)\n",
    "# # model.add(layers.Dropout(rate, noise_shape=None, seed=None))\n",
    "# model.add(Dense(h[2]))\n",
    "# model.add(act3)\n",
    "act=layers.LeakyReLU(alpha=0.01)\n",
    "model.add(Dense(len_data[1]))\n",
    "#############################################\n",
    "import os\n",
    "from natsort import natsorted\n",
    "\n",
    "# def _parse_function(example_proto):\n",
    "#     print('1')\n",
    "#     features = {\"X\": tf.FixedLenFeature((3*257), tf.float32),\n",
    "#               \"Y\": tf.FixedLenFeature((257), tf.float32)}\n",
    "#     parsed_features = tf.parse_single_example(example_proto, features)\n",
    "#     print(\"i was here\")\n",
    "#     print('2')\n",
    "#     return parsed_features[\"X\"], parsed_features[\"Y\"]\n",
    "\n",
    "# tfrecord_path = os.path.normpath(os.path.join(Data_path,tfrecord_folder_parent,tfrecord_folder))\n",
    "# sorted_names = natsorted(os.listdir(tfrecord_path))\n",
    "# trainfilenames = []\n",
    "# for i in sorted_names:\n",
    "#     trainfilenames.append(os.path.normpath(os.path.join(tfrecord_path,i)))\n",
    "# filenames = tf.placeholder(tf.string, shape=[None])\n",
    "# dataset = tf.data.TFRecordDataset(filenames)\n",
    "# dataset = dataset.map(_parse_function)  # Parse the record into tensors.\n",
    "# dataset = dataset.repeat()  # Repeat the input indefinitely.\n",
    "# dataset = dataset.batch(batch_size)\n",
    "# iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "# # orig_path = os.getcwd()\n",
    "# tfrecord_path_x = os.path.normpath(os.path.join(Data_path,tfrecord_folder_parent,tfrecord_folder))\n",
    "# sorted_names_x = natsorted(os.listdir(tfrecord_path_x))\n",
    "# trainfilenames_x = []\n",
    "# for i in sorted_names_x:\n",
    "#     trainfilenames_x.append(os.path.normpath(os.path.join(tfrecord_path,i)))\n",
    "# filenames_x = tf.placeholder(tf.string, shape=[None])\n",
    "# dataset_x = tf.data.TFRecordDataset(filenames_x)\n",
    "# dataset_x = dataset_x.map(_parse_function)  # Parse the record into tensors.\n",
    "# dataset_x = dataset_x.repeat()  # Repeat the input indefinitely.\n",
    "# dataset_x = dataset_x.batch(batch_size)\n",
    "# iterator_x = dataset_x.make_initializable_iterator()\n",
    "\n",
    "########################\n",
    "visible = w*len_data[1]\n",
    "hidden = h[0]\n",
    "visible1 = h[0]\n",
    "hidden1 = h[1]\n",
    "visible2 = h[1]\n",
    "hidden2 = len_data[1]\n",
    "\n",
    "layer1 = rbm_layer(visible, hidden, 10, batch_size, 0.001, [np.eye(visible)], [np.zeros((1,visible))], 1, len_data[0],dirs)\n",
    "# layer2 = rbm_layer(visible1, hidden1, 50, batch_size, 0.01, [np.eye(visible),layer1[0]], [np.zeros((1,visible)),layer1[2]], 2, len_data[0], dirs)\n",
    "# layer3 = rbm_layer(visible2, hidden2, 50, batch_size, 0.01, [np.eye(visible),layer1[0],layer2[0]], [np.zeros((1,visible)),layer1[2],layer2[2]], 3, len_data[0], dirs)\n",
    "\n",
    "###############################\n",
    "\n",
    "# tfrecord_path_val = os.path.normpath(os.path.join(Data_path,tfrecord_folder_parent,tfrecord_val_folder))\n",
    "# sorted_names_val = natsorted(os.listdir(tfrecord_path_val))\n",
    "# trainfilenames_val = []\n",
    "# for i in sorted_names_val:\n",
    "#     trainfilenames_val.append(os.path.normpath(os.path.join(tfrecord_path_val,i)))\n",
    "# filenames_val = tf.placeholder(tf.string, shape=[None])\n",
    "# dataset_val = tf.data.TFRecordDataset(filenames_val)\n",
    "# dataset_val = dataset_val.map(_parse_function)  # Parse the record into tensors.\n",
    "# dataset_val = dataset_val.repeat()  # Repeat the input indefinitely.\n",
    "# dataset_val = dataset_val.batch(128)\n",
    "# iterator_val = dataset_val.make_initializable_iterator()\n",
    "\n",
    "# epochs_num = 50\n",
    "# steps = len_data[0] // batch_size\n",
    "# val_steps = val_len[0] // batch_size\n",
    "# # You can feed the initializer with the appropriate filenames for the current\n",
    "# # phase of execution, e.g. training vs. validation.\n",
    "# # next_elem = iterator_val.get_next()\n",
    "# # Initialize `iterator` with training data.\n",
    "\n",
    "# if not os.path.exists(os.path.join(Data_path,\"checkpoints\",ckpt_folder)):\n",
    "#     os.makedirs(os.path.join(Data_path,\"checkpoints\",ckpt_folder))\n",
    "\n",
    "# print(datetime.datetime.now())\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     sess.run(iterator.initializer, feed_dict={filenames: trainfilenames})\n",
    "#     sess.run(iterator_val.initializer, feed_dict={filenames_val: trainfilenames_val})\n",
    "#     print(\"initialized\")\n",
    "#     checkpoint_path = os.path.normpath(os.path.join(Data_path,\"checkpoints\",ckpt_folder,\"weights.{epoch:02d}.hdf5\"))\n",
    "#     checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "#     cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#         checkpoint_path, verbose=1, save_best_only=True, save_weights_only=True)\n",
    "#         # Save weights, every 5-epochs.\n",
    "# #         period=1)\n",
    "#     early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)\n",
    "#     opt = tf.keras.optimizers.Adamax()\n",
    "# #     opt = tf.train.AdamOptimizer()\n",
    "# #     opt = tf.keras.optimizers.SGD()\n",
    "#     model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "#     history = model.fit( iterator, steps_per_epoch=steps,epochs=epochs_num, callbacks = [cp_callback,early_stop], verbose=1,validation_data=iterator_val,validation_steps=val_steps)\n",
    "# #     model.save(os.path.normpath(os.path.join(Data_path, 'models', \"model_3h_dataset.h5\")))\n",
    "# #     tf.keras.models.save_model(model, os.path.normpath(os.path.join(Data_path, 'models', \"model_3h_dataset.h5\")))\n",
    "# #     model.save_weights(os.path.normpath(os.path.join(Data_path, 'models', \"model_3h_dataset.h5\")))\n",
    "#     model_json = model.to_json()\n",
    "#     with open(os.path.normpath(os.path.join(Data_path, 'models', \"model_3.json\")), \"w\") as json_file:\n",
    "#         json_file.write(model_json)\n",
    "#     # # serialize weights to HDF5\n",
    "#     model.save_weights(os.path.normpath(os.path.join(Data_path, 'models', \"model_3.h5\")))\n",
    "#     print(\"Saved model to disk\")\n",
    "    \n",
    "# print(datetime.datetime.now())\n",
    "# %matplotlib inline\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train'], loc='upper left')\n",
    "# plt.show()\n",
    "# plt.savefig(os.path.normpath(os.path.join(Data_path,'images',ckpt_folder+'.png')))\n",
    "# # model_json = model.to_json()\n",
    "# # with open(\"model_10h_dataset.json\", \"w\") as json_file:\n",
    "# #     json_file.write(model_json)\n",
    "# # model.save_weights(\"model_10h_dataset.h5\")\n",
    "# # print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff/10hdata'\n",
    "mixed_folder = os.path.normpath(os.path.join(write_path,'mixed_log_10h_norm2'))\n",
    "h5f = h5py.File(mixed_folder+'.hdf5','r')\n",
    "ftr = h5f['mixed_log_10h_norm2'][0:126]\n",
    "h5f.close()\n",
    "mixed_folder = os.path.normpath(os.path.join(write_path,'mixed_phase_10h_nozeroinsert'))\n",
    "h5f = h5py.File(mixed_folder+'.hdf5','r')\n",
    "ftr_phase = h5f['mixed_phase_10h_nozeroinsert'][0:126]\n",
    "h5f.close()\n",
    "mixed_folder = os.path.normpath(os.path.join(write_path,'mixed_log_10h_nozeroinsert'))\n",
    "h5f = h5py.File(mixed_folder+'.hdf5','r')\n",
    "ftr_raw = h5f['mixed_log_10h_nozeroinsert'][0:126]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = np.matmul(ftr,layer1[0])+layer1[2]\n",
    "# hidden2 = np.matmul(hidden1,layer2[0])+layer2[2]\n",
    "# hidden3 = np.matmul(hidden2,layer3[0])+layer3[2]\n",
    "hidden1_b = np.matmul(hidden1,layer1[0].T)+layer1[1]\n",
    "# hidden2_b = np.matmul(hidden3_b,layer2[0].T)+layer2[1]\n",
    "# hidden1_b = np.matmul(hidden2_b,layer1[0].T)+layer1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.40029923e+30,  6.68745183e+30,  2.72759566e+30, ...,\n",
       "        -1.51103747e+31, -2.52782762e+30, -5.44645381e+30],\n",
       "       [-1.84473708e+30,  8.80999130e+30,  3.59330291e+30, ...,\n",
       "        -1.99063805e+31, -3.33013789e+30, -7.17510168e+30],\n",
       "       [-1.68141755e+30,  8.03001352e+30,  3.27517408e+30, ...,\n",
       "        -1.81438742e+31, -3.03530053e+30, -6.53983715e+30],\n",
       "       ...,\n",
       "       [-2.59491908e+30,  1.23927058e+31,  5.05458202e+30, ...,\n",
       "        -2.80015388e+31, -4.68437025e+30, -1.00929276e+31],\n",
       "       [-2.59491908e+30,  1.23927058e+31,  5.05458202e+30, ...,\n",
       "        -2.80015388e+31, -4.68437025e+30, -1.00929276e+31],\n",
       "       [-2.59491908e+30,  1.23927058e+31,  5.05458202e+30, ...,\n",
       "        -2.80015388e+31, -4.68437025e+30, -1.00929276e+31]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28766647,  0.11526573, -0.7069241 , ..., -0.55612373,\n",
       "        -0.5525803 , -0.50696164],\n",
       "       [ 0.12223668,  0.26682785, -0.4372746 , ..., -0.99636066,\n",
       "        -1.0043348 , -1.5150769 ],\n",
       "       [ 0.8128672 ,  0.6103882 , -0.9415356 , ..., -1.1297925 ,\n",
       "        -0.9657317 , -0.59864193],\n",
       "       ...,\n",
       "       [-4.825073  , -5.533287  , -4.9773455 , ..., -2.2312639 ,\n",
       "        -2.2086217 , -1.930099  ],\n",
       "       [-4.825073  , -5.533287  , -4.9773455 , ..., -2.2312639 ,\n",
       "        -2.2086217 , -1.930099  ],\n",
       "       [-4.825073  , -5.533287  , -4.9773455 , ..., -2.2312639 ,\n",
       "        -2.2086217 , -1.930099  ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:50: RuntimeWarning: overflow encountered in power\n",
      "C:\\Users\\ASUS\\Anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean = np.loadtxt(os.path.normpath(os.path.join(write_path,'mean_mixed_log.txt')))\n",
    "std = np.loadtxt(os.path.normpath(os.path.join(write_path,'std_mixed_log.txt')))\n",
    "hidden1_b_unnorm = (hidden1_b*std)+mean\n",
    "recon = reconstruct(hidden1_b_unnorm, ftr_phase)\n",
    "import sounddevice as sd\n",
    "sd.play(recon,16000)\n",
    "\n",
    "Pxx, freqs, bins, im = plt.specgram(recon, NFFT=512, Fs=16000, noverlap=256)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:50: RuntimeWarning: overflow encountered in power\n",
      "C:\\Users\\ASUS\\Anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "recon = reconstruct(hidden1_b, ftr_phase)\n",
    "import sounddevice as sd\n",
    "sd.play(recon,16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(771,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py \n",
    "import tensorflow as tf\n",
    "hh = h5py.File('ftr_refrmd_10h.hdf5', 'r')\n",
    "d=hh['ftr_refrmd_10h'][0]\n",
    "len_data=d.shape\n",
    "hh.close()\n",
    "len_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((?, 257), (?,)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
