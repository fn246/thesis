{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from pystoi.stoi import stoi\n",
    "import mir_eval #https://github.com/craffel/mir_eval\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "# import keras\n",
    "from scipy.io import wavfile\n",
    "# from pypesq import pesq #https://github.com/vBaiCai/python-pesq\n",
    "# import vqmetrics\n",
    "from natsort import natsorted\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab \n",
    "import soundfile as sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define reconstruct function to reconstruct sound from framed signal.\n",
    "def reconstruct(wave,angle):\n",
    "    recon = np.sqrt(np.power(10, wave))\n",
    "    recon1 = recon*np.cos(angle)+recon*np.sin(angle)*1j\n",
    "    recon = librosa.core.istft((recon1.T), hop_length=256, win_length=512, window='hann')\n",
    "    return recon\n",
    "def change_order(first):\n",
    "    sec=np.copy(first)\n",
    "    sec=np.copy(first)\n",
    "    sec[0] = first[5]\n",
    "    sec[1] = first[4]\n",
    "    sec[2] = first[3]\n",
    "    sec[5] = first[2]\n",
    "    sec[4] = first[1]\n",
    "    sec[3] = first[0]\n",
    "    return sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "json_file = open(os.path.normpath(os.path.join(Data_path,'models','model_36.json')),'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(os.path.normpath(os.path.join(Data_path,'models','model_36.h5')))\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "json_file = open(os.path.normpath(os.path.join(Data_path,'models','model_44.json')),'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(os.path.normpath(os.path.join(Data_path,'checkpoints','44','weights.01.hdf5')))\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_61_input to have shape (257,) but got array with shape (771,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8931d2b5986f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mdft_signal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabslt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1e-7\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabslt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mmixed_files\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'test_log2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename44\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_log\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mrecon_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_phase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mrecon_mixed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmixed_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_phase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1094\u001b[0m       \u001b[1;31m# batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m       x, _, _ = self._standardize_user_data(\n\u001b[1;32m-> 1096\u001b[1;33m           x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[0;32m   1097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m     if (self.run_eagerly or (isinstance(x, iterator_ops.EagerIterator) and\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[0;32m   2380\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2382\u001b[1;33m         exception_prefix='input')\n\u001b[0m\u001b[0;32m   2383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2384\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    360\u001b[0m                 \u001b[1;34m'Error when checking '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    363\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_61_input to have shape (257,) but got array with shape (771,)"
     ]
    }
   ],
   "source": [
    "stoi_eval=[]\n",
    "sdr=[]\n",
    "stoi_mixed=[]\n",
    "sdr_mixed=[]\n",
    "mean_sdr=[]\n",
    "mean_sdr_mixed=[]\n",
    "mean_stoi=[]\n",
    "mean_stoi_mixed=[]\n",
    "# orig_path=os.getcwd()\n",
    "Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "write_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff/test_data'\n",
    "parent = 'results'\n",
    "foldername = 'test'\n",
    "# input_test = 'ftr_refrmd_test'\n",
    "input_test = 'test_log2_norm2'\n",
    "image = 'images'\n",
    "inputs = os.listdir(os.path.normpath(os.path.join(write_path,input_test)))\n",
    "inputs = natsorted(inputs)\n",
    "mixed = os.listdir(os.path.normpath(os.path.join(write_path,'test_log2')))\n",
    "mixed = natsorted(mixed)\n",
    "clean1 = os.listdir(os.path.normpath(os.path.join(write_path,'test_log','clean')))\n",
    "clean1 = natsorted(clean1)\n",
    "clean = clean1.copy()\n",
    "j=0\n",
    "print(len(clean))\n",
    "for i in range(len(inputs)-1):\n",
    "    clean=np.concatenate((clean,clean1),axis=0)\n",
    "phase = os.listdir(os.path.join(write_path,'test_phase2'))\n",
    "phase = natsorted(phase)\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername)):\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername))\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername,'pesq')):\n",
    "#     print('creating pesq')\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername,'pesq'))\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername,'sdr')):\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername,'sdr'))\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername,'stoi')):\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername,'stoi'))\n",
    "for filename1,filename2,filename4 in zip(inputs,phase,mixed):\n",
    "    print(filename1)\n",
    "    print(filename2)\n",
    "    print(filename4)\n",
    "    a = os.listdir(os.path.join(write_path,input_test,filename1))\n",
    "    b = os.listdir(os.path.join(write_path,'test_phase2',filename2))\n",
    "    print('blah')\n",
    "    c = os.listdir(os.path.join(write_path,'test_log2',filename4))\n",
    "    stoi_eval=[]\n",
    "    pesq_eval=[]\n",
    "    sdr=[]\n",
    "    stoi_mixed=[]\n",
    "    sdr_mixed=[]\n",
    "    if not os.path.exists(os.path.join(Data_path,parent,foldername,filename1)):\n",
    "        os.mkdir(os.path.join(Data_path,parent,foldername,filename1))\n",
    "    for filename11,filename22,filename33,filename44 in zip(a,b,clean,c):\n",
    "        X_log=np.loadtxt(os.path.join(write_path,input_test,filename1,filename11),delimiter=',')\n",
    "        X_phase=np.loadtxt(os.path.join(write_path,'test_phase2',filename2,filename22),delimiter=',')\n",
    "        target = np.loadtxt(os.path.join(write_path,'test_log','clean',filename33),delimiter=',')\n",
    "        framed_data=librosa.core.stft(target, n_fft=512, hop_length=256, win_length=512, window='hann')\n",
    "        abslt=np.absolute(framed_data)**2\n",
    "        dft_signal=np.log10(abslt+1e-7*np.ones(np.shape(abslt)))\n",
    "        mixed_files=np.loadtxt(os.path.join(write_path,'test_log2',filename4,filename44),delimiter=',')\n",
    "        prediction = loaded_model.predict(X_log)\n",
    "        recon_out = reconstruct(prediction, X_phase)\n",
    "        recon_mixed = reconstruct(mixed_files, X_phase)\n",
    "        recon_clean = reconstruct(dft_signal.T, X_phase)\n",
    "        sf.write(os.path.normpath(os.path.join(Data_path,parent,foldername,filename1)+'\\\\'+filename11.replace('.txt','')+'.wav'),recon_out,16000)\n",
    "        target = target[0:len(recon_out)]\n",
    "        #target = np.reshape(target,(1,len(recon_out)))\n",
    "        #recon_out=np.reshape(recon_out,(1,len(recon_out)))\n",
    "#         pesq_eval.append(get_pesq(target, recon_out,16000))\n",
    "        sdr.append(mir_eval.separation.bss_eval_sources(target, recon_out, compute_permutation=False)[0][0])\n",
    "        stoi_eval.append(stoi(target, recon_out, 16000, extended=False))\n",
    "        sdr_mixed.append(mir_eval.separation.bss_eval_sources(target, recon_mixed, compute_permutation=False)[0][0])\n",
    "        stoi_mixed.append(stoi(target, recon_mixed, 16000, extended=False))\n",
    "    mean_stoi.append(np.mean(stoi_eval))\n",
    "    mean_stoi_mixed.append(np.mean(stoi_mixed))\n",
    "    mean_sdr.append(np.mean(sdr))\n",
    "    mean_sdr_mixed.append(np.mean(sdr_mixed))\n",
    "mean_sdr2 = change_order(mean_sdr)\n",
    "mean_stoi2 = change_order(mean_stoi)\n",
    "mean_sdr_mixed2 = change_order(mean_sdr_mixed)\n",
    "mean_stoi_mixed2 = change_order(mean_stoi_mixed)\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername,'sdr')+'\\\\'+'predictedsdr.txt',mean_sdr2, fmt='%1.4f')\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername,'sdr')+'\\\\'+'mixedsdr.txt',mean_sdr_mixed2, fmt='%1.4f')\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername,'stoi')+'\\\\'+'predictedstoi.txt',mean_stoi2, fmt='%1.4f')\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername,'stoi')+'\\\\'+'mixedstoi.txt',mean_stoi_mixed2, fmt='%1.4f')\n",
    "if not os.path.exists(os.path.join(Data_path, parent, image, foldername)):\n",
    "    os.makedirs(os.path.join(Data_path, parent, image, foldername))\n",
    "plt.plot([-9,-6,-3,0,3,6], mean_sdr2, 'r-o', [-9,-6,-3,0,3,6], mean_sdr_mixed2, 'b-o')\n",
    "plt.gca().legend(('pred','mix'))\n",
    "x=[-9,-6,-3,0,3,6]\n",
    "\n",
    "plt.show\n",
    "plt.savefig(os.path.normpath(os.path.join(Data_path, parent, image, foldername, 'sdr.png')))\n",
    "plt.close()\n",
    "plt.plot([-9,-6,-3,0,3,6], mean_stoi2, 'r-o', [-9,-6,-3,0,3,6], mean_stoi_mixed2, 'b-o')\n",
    "plt.gca().legend(('pred','mix'))\n",
    "\n",
    "plt.show\n",
    "plt.savefig(os.path.normpath(os.path.join(Data_path, parent, image, foldername, 'stoi.png')))\n",
    "plt.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:\\\\studies\\\\university\\\\thesis\\\\speech_separation_codes\\\\du16\\\\donesomestuff\\\\test_data\\\\test_log2_semi_norm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-170890eb1563>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0minput_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'test_log2_semi_norm'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'images'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnatsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mmixed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'test_log2_semi'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:\\\\studies\\\\university\\\\thesis\\\\speech_separation_codes\\\\du16\\\\donesomestuff\\\\test_data\\\\test_log2_semi_norm'"
     ]
    }
   ],
   "source": [
    "model_num= 42\n",
    "ckpt_num= 38\n",
    "import tensorflow as tf\n",
    "import os\n",
    "# Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "# json_file = open(os.path.normpath(os.path.join(Data_path,'models','model_'+str(model_num)+'.json')),'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# loaded_model.load_weights(os.path.normpath(os.path.join(Data_path,'models','model_'+str(model_num)+'.h5')))\n",
    "# print(\"Loaded model from disk\")\n",
    "# print(model_num)\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "json_file = open(os.path.normpath(os.path.join(Data_path,'models','model_'+str(model_num)+'.json')),'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(os.path.normpath(os.path.join(Data_path,'checkpoints',str(model_num),'weights.'+str(ckpt_num)+'.hdf5')))\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "stoi_eval=[]\n",
    "sdr=[]\n",
    "stoi_mixed=[]\n",
    "sdr_mixed=[]\n",
    "mean_sdr=[]\n",
    "mean_sdr_mixed=[]\n",
    "mean_stoi=[]\n",
    "mean_stoi_mixed=[]\n",
    "# orig_path=os.getcwd()\n",
    "Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "write_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff/test_data'\n",
    "w = 3\n",
    "parent = 'results'\n",
    "# foldername = 'results_'+str(model_num)+'_2'\n",
    "# foldername = 'results_'+str(model_num)+'_ckpt'+str(ckpt_num)\n",
    "foldername = 'results_'+str(model_num)\n",
    "# foldername = 'test'\n",
    "# input_test = 'ftr_refrmd_test_norm'\n",
    "input_test = 'test_log2_semi_norm'\n",
    "image = 'images'\n",
    "inputs = os.listdir(os.path.normpath(os.path.join(write_path,input_test)))\n",
    "inputs = natsorted(inputs)\n",
    "mixed = os.listdir(os.path.normpath(os.path.join(write_path,'test_log2_semi')))\n",
    "mixed = natsorted(mixed)\n",
    "clean1 = os.listdir(os.path.normpath(os.path.join(write_path,'test_log_semi','clean')))\n",
    "clean1 = natsorted(clean1)\n",
    "clean = clean1.copy()\n",
    "j=0\n",
    "print(len(clean))\n",
    "for i in range(len(inputs)-1):\n",
    "    clean=np.concatenate((clean,clean1),axis=0)\n",
    "phase = os.listdir(os.path.join(write_path,'test_phase2_semi'))\n",
    "phase = natsorted(phase)\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername)):\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername))\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername,'pesq')):\n",
    "#     print('creating pesq')\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername,'pesq'))\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername,'sdr')):\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername,'sdr'))\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername,'stoi')):\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername,'stoi'))\n",
    "for filename1,filename2,filename4 in zip(inputs,phase,mixed):\n",
    "    print(filename1)\n",
    "    print(filename2)\n",
    "    print(filename4)\n",
    "    a = os.listdir(os.path.join(write_path,input_test,filename1))\n",
    "    b = os.listdir(os.path.join(write_path,'test_phase2_semi',filename2))\n",
    "    print('blah')\n",
    "    c = os.listdir(os.path.join(write_path,'test_log2_semi',filename4))\n",
    "    stoi_eval=[]\n",
    "    pesq_eval=[]\n",
    "    sdr=[]\n",
    "    stoi_mixed=[]\n",
    "    sdr_mixed=[]\n",
    "    if not os.path.exists(os.path.join(Data_path,parent,foldername,filename1)):\n",
    "        os.mkdir(os.path.join(Data_path,parent,foldername,filename1))\n",
    "    for filename11,filename22,filename33,filename44 in zip(a,b,clean,c):\n",
    "        X_log=np.loadtxt(os.path.join(write_path,input_test,filename1,filename11),delimiter=',')\n",
    "        X_phase=np.loadtxt(os.path.join(write_path,'test_phase2_semi',filename2,filename22),delimiter=',')\n",
    "        target = np.loadtxt(os.path.normpath(os.path.join(write_path,'test_log_semi','clean',filename33)),dtype='float32',delimiter=',')\n",
    "        framed_data=librosa.core.stft(target, n_fft=512, hop_length=256, win_length=512, window='hann')\n",
    "        abslt=np.absolute(framed_data)**2\n",
    "        dft_signal=np.log10(abslt+1e-7*np.ones(np.shape(abslt)))\n",
    "        mixed_files=np.loadtxt(os.path.join(write_path,'test_log2_semi',filename4,filename44),delimiter=',')\n",
    "        prediction = loaded_model.predict(X_log)\n",
    "        recon_out = reconstruct(prediction, X_phase)\n",
    "        recon_mixed = reconstruct(mixed_files, X_phase)\n",
    "        recon_clean = reconstruct(dft_signal.T, X_phase)\n",
    "        sf.write(os.path.normpath(os.path.join(Data_path,parent,foldername,filename1)+'\\\\'+filename11.replace('.txt','')+'.wav'),recon_out,16000)\n",
    "        target = target[0:len(recon_out)]\n",
    "        #target = np.reshape(target,(1,len(recon_out)))\n",
    "        #recon_out=np.reshape(recon_out,(1,len(recon_out)))\n",
    "#         pesq_eval.append(get_pesq(target, recon_out,16000))\n",
    "        sdr.append(mir_eval.separation.bss_eval_sources(target, recon_out, compute_permutation=False)[0][0])\n",
    "        stoi_eval.append(stoi(target, recon_out, 16000, extended=False))\n",
    "        sdr_mixed.append(mir_eval.separation.bss_eval_sources(target, recon_mixed, compute_permutation=False)[0][0])\n",
    "        stoi_mixed.append(stoi(target, recon_mixed, 16000, extended=False))\n",
    "    mean_stoi.append(np.mean(stoi_eval))\n",
    "    mean_stoi_mixed.append(np.mean(stoi_mixed))\n",
    "    mean_sdr.append(np.mean(sdr))\n",
    "    mean_sdr_mixed.append(np.mean(sdr_mixed))\n",
    "mean_sdr2 = change_order(mean_sdr)\n",
    "mean_stoi2 = change_order(mean_stoi)\n",
    "mean_sdr_mixed2 = change_order(mean_sdr_mixed)\n",
    "mean_stoi_mixed2 = change_order(mean_stoi_mixed)\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername,'sdr')+'\\\\'+'predictedsdr.txt',mean_sdr2, fmt='%1.4f')\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername,'sdr')+'\\\\'+'mixedsdr.txt',mean_sdr_mixed2, fmt='%1.4f')\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername,'stoi')+'\\\\'+'predictedstoi.txt',mean_stoi2, fmt='%1.4f')\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername,'stoi')+'\\\\'+'mixedstoi.txt',mean_stoi_mixed2, fmt='%1.4f')\n",
    "if not os.path.exists(os.path.join(Data_path, parent, image, foldername)):\n",
    "    os.makedirs(os.path.join(Data_path, parent, image, foldername))\n",
    "plt.plot([-9,-6,-3,0,3,6], mean_sdr2, 'r-o', [-9,-6,-3,0,3,6], mean_sdr_mixed2, 'b-o')\n",
    "plt.gca().legend(('pred','mix'))\n",
    "x=[-9,-6,-3,0,3,6]\n",
    "\n",
    "plt.show\n",
    "plt.savefig(os.path.normpath(os.path.join(Data_path, parent, image, foldername, 'sdr.png')))\n",
    "plt.close()\n",
    "plt.plot([-9,-6,-3,0,3,6], mean_stoi2, 'r-o', [-9,-6,-3,0,3,6], mean_stoi_mixed2, 'b-o')\n",
    "plt.gca().legend(('pred','mix'))\n",
    "\n",
    "plt.show\n",
    "plt.savefig(os.path.normpath(os.path.join(Data_path, parent, image, foldername, 'stoi.png')))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\ASUS\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loaded model from disk\n",
      "45\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n"
     ]
    }
   ],
   "source": [
    "model_num= 45\n",
    "ckpt_num= '03'\n",
    "import tensorflow as tf\n",
    "import os\n",
    "Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "foldername = 'results_'+str(model_num)+'_2'\n",
    "json_file = open(os.path.normpath(os.path.join(Data_path,'models','model_'+str(model_num)+'.json')),'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(os.path.normpath(os.path.join(Data_path,'models','model_'+str(model_num)+'.h5')))\n",
    "print(\"Loaded model from disk\")\n",
    "print(model_num)\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import os\n",
    "# foldername = 'results_'+str(model_num)+'_ckpt'+ckpt_num\n",
    "# Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "# json_file = open(os.path.normpath(os.path.join(Data_path,'models','model_'+str(model_num)+'.json')),'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# loaded_model.load_weights(os.path.normpath(os.path.join(Data_path,'checkpoints',str(model_num),'weights.'+ckpt_num+'.hdf5')))\n",
    "# print(\"Loaded model from disk\")\n",
    "\n",
    "stoi_eval=[]\n",
    "sdr=[]\n",
    "stoi_mixed=[]\n",
    "sdr_mixed=[]\n",
    "mean_sdr=[]\n",
    "mean_sdr_mixed=[]\n",
    "mean_stoi=[]\n",
    "mean_stoi_mixed=[]\n",
    "# orig_path=os.getcwd()\n",
    "Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "write_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff/test_data'\n",
    "parent = 'results'\n",
    "# foldername = 'results_'+str(model_num)\n",
    "# foldername = 'test'\n",
    "# input_test = 'ftr_refrmd_test_norm'\n",
    "input_test = 'test_log2_norm2'\n",
    "image = 'images'\n",
    "inputs = os.listdir(os.path.normpath(os.path.join(write_path,input_test)))\n",
    "inputs = natsorted(inputs)\n",
    "mixed = os.listdir(os.path.normpath(os.path.join(write_path,'test_log2')))\n",
    "mixed = natsorted(mixed)\n",
    "clean1 = os.listdir(os.path.normpath(os.path.join(write_path,'test_log','clean')))\n",
    "clean1 = natsorted(clean1)\n",
    "clean = clean1.copy()\n",
    "j=0\n",
    "print(len(clean))\n",
    "for i in range(len(inputs)-1):\n",
    "    clean=np.concatenate((clean,clean1),axis=0)\n",
    "phase = os.listdir(os.path.join(write_path,'test_phase2'))\n",
    "phase = natsorted(phase)\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername)):\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername))\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername,'pesq')):\n",
    "#     print('creating pesq')\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername,'pesq'))\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername,'sdr')):\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername,'sdr'))\n",
    "if not os.path.exists(os.path.join(Data_path,parent,foldername,'stoi')):\n",
    "    os.makedirs(os.path.join(Data_path,parent,foldername,'stoi'))\n",
    "for filename1,filename2,filename4 in zip(inputs,phase,mixed):\n",
    "    print(filename1)\n",
    "    print(filename2)\n",
    "    print(filename4)\n",
    "    a = os.listdir(os.path.join(write_path,input_test,filename1))\n",
    "    b = os.listdir(os.path.join(write_path,'test_phase2',filename2))\n",
    "    print('blah')\n",
    "    c = os.listdir(os.path.join(write_path,'test_log2',filename4))\n",
    "    stoi_eval=[]\n",
    "    pesq_eval=[]\n",
    "    sdr=[]\n",
    "    stoi_mixed=[]\n",
    "    sdr_mixed=[]\n",
    "    if not os.path.exists(os.path.join(Data_path,parent,foldername,filename1)):\n",
    "        os.mkdir(os.path.join(Data_path,parent,foldername,filename1))\n",
    "    for filename11,filename22,filename33,filename44 in zip(a,b,clean,c):\n",
    "        X_log=np.loadtxt(os.path.join(write_path,input_test,filename1,filename11),delimiter=',')\n",
    "        X_phase=np.loadtxt(os.path.join(write_path,'test_phase2',filename2,filename22),delimiter=',')\n",
    "        target = np.loadtxt(os.path.normpath(os.path.join(write_path,'test_log','clean',filename33)),dtype='float32',delimiter=',')\n",
    "        framed_data=librosa.core.stft(target, n_fft=512, hop_length=256, win_length=512, window='hann')\n",
    "        abslt=np.absolute(framed_data)**2\n",
    "        dft_signal=np.log10(abslt+(1e-7*np.ones(np.shape(abslt))))\n",
    "        mixed_files=np.loadtxt(os.path.join(write_path,'test_log2',filename4,filename44),delimiter=',')\n",
    "        prediction = loaded_model.predict(X_log)\n",
    "        recon_out = reconstruct(prediction, X_phase)\n",
    "        recon_mixed = reconstruct(mixed_files, X_phase)\n",
    "        recon_clean = reconstruct(dft_signal.T, X_phase)\n",
    "        sf.write(os.path.normpath(os.path.join(Data_path,parent,foldername,filename1)+'\\\\'+filename11.replace('.txt','')+'.wav'),recon_out,16000)\n",
    "        target = target[0:len(recon_out)]\n",
    "        #target = np.reshape(target,(1,len(recon_out)))\n",
    "        #recon_out=np.reshape(recon_out,(1,len(recon_out)))\n",
    "#         pesq_eval.append(get_pesq(target, recon_out,16000))\n",
    "        sdr.append(mir_eval.separation.bss_eval_sources(target, recon_out, compute_permutation=False)[0][0])\n",
    "        stoi_eval.append(stoi(target, recon_out, 16000, extended=False))\n",
    "        sdr_mixed.append(mir_eval.separation.bss_eval_sources(target, recon_mixed, compute_permutation=False)[0][0])\n",
    "        stoi_mixed.append(stoi(target, recon_mixed, 16000, extended=False))\n",
    "    mean_stoi.append(np.mean(stoi_eval))\n",
    "    mean_stoi_mixed.append(np.mean(stoi_mixed))\n",
    "    mean_sdr.append(np.mean(sdr))\n",
    "    mean_sdr_mixed.append(np.mean(sdr_mixed))\n",
    "mean_sdr2 = change_order(mean_sdr)\n",
    "mean_stoi2 = change_order(mean_stoi)\n",
    "mean_sdr_mixed2 = change_order(mean_sdr_mixed)\n",
    "mean_stoi_mixed2 = change_order(mean_stoi_mixed)\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername,'sdr')+'\\\\'+'predictedsdr.txt',mean_sdr2, fmt='%1.4f')\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername,'sdr')+'\\\\'+'mixedsdr.txt',mean_sdr_mixed2, fmt='%1.4f')\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername,'stoi')+'\\\\'+'predictedstoi.txt',mean_stoi2, fmt='%1.4f')\n",
    "np.savetxt(os.path.join(Data_path,parent,foldername,'stoi')+'\\\\'+'mixedstoi.txt',mean_stoi_mixed2, fmt='%1.4f')\n",
    "if not os.path.exists(os.path.join(Data_path, parent, image, foldername)):\n",
    "    os.makedirs(os.path.join(Data_path, parent, image, foldername))\n",
    "plt.plot([-9,-6,-3,0,3,6], mean_sdr2, 'r-o', [-9,-6,-3,0,3,6], mean_sdr_mixed2, 'b-o')\n",
    "plt.gca().legend(('pred','mix'))\n",
    "x=[-9,-6,-3,0,3,6]\n",
    "\n",
    "plt.show\n",
    "plt.savefig(os.path.normpath(os.path.join(Data_path, parent, image, foldername, 'sdr.png')))\n",
    "plt.close()\n",
    "plt.plot([-9,-6,-3,0,3,6], mean_stoi2, 'r-o', [-9,-6,-3,0,3,6], mean_stoi_mixed2, 'b-o')\n",
    "plt.gca().legend(('pred','mix'))\n",
    "\n",
    "plt.show\n",
    "plt.savefig(os.path.normpath(os.path.join(Data_path, parent, image, foldername, 'stoi.png')))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n",
      "6\n",
      "6\n",
      "6\n",
      "blah\n",
      "m3\n",
      "m3\n",
      "m3\n",
      "blah\n",
      "m6\n",
      "m6\n",
      "m6\n",
      "blah\n",
      "m9\n",
      "m9\n",
      "m9\n",
      "blah\n",
      "Loaded model from disk\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "blah\n",
      "3\n",
      "3\n",
      "3\n",
      "blah\n"
     ]
    }
   ],
   "source": [
    "model_num= 45\n",
    "for ckpt_num in range(1,50):\n",
    "    import tensorflow as tf\n",
    "    import os\n",
    "    foldername = 'results_'+str(model_num)+'_ckpt'+str(ckpt_num).zfill(2)\n",
    "    Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "    json_file = open(os.path.normpath(os.path.join(Data_path,'models','model_'+str(model_num)+'.json')),'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(os.path.normpath(os.path.join(Data_path,'checkpoints',str(model_num),'weights.'+str(ckpt_num).zfill(2)+'.hdf5')))\n",
    "    print(\"Loaded model from disk\")\n",
    "\n",
    "    stoi_eval=[]\n",
    "    sdr=[]\n",
    "    stoi_mixed=[]\n",
    "    sdr_mixed=[]\n",
    "    mean_sdr=[]\n",
    "    mean_sdr_mixed=[]\n",
    "    mean_stoi=[]\n",
    "    mean_stoi_mixed=[]\n",
    "    # orig_path=os.getcwd()\n",
    "    Data_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff'\n",
    "    write_path = 'D:/studies/university/thesis/speech_separation_codes/du16/donesomestuff/test_data'\n",
    "    parent = 'results'\n",
    "    # foldername = 'results_'+str(model_num)\n",
    "    # foldername = 'test'\n",
    "    # input_test = 'ftr_refrmd_test_norm'\n",
    "    input_test = 'test_log2_norm2'\n",
    "    image = 'images'\n",
    "    inputs = os.listdir(os.path.normpath(os.path.join(write_path,input_test)))\n",
    "    inputs = natsorted(inputs)\n",
    "    mixed = os.listdir(os.path.normpath(os.path.join(write_path,'test_log2')))\n",
    "    mixed = natsorted(mixed)\n",
    "    clean1 = os.listdir(os.path.normpath(os.path.join(write_path,'test_log','clean')))\n",
    "    clean1 = natsorted(clean1)\n",
    "    clean = clean1.copy()\n",
    "    j=0\n",
    "    print(len(clean))\n",
    "    for i in range(len(inputs)-1):\n",
    "        clean=np.concatenate((clean,clean1),axis=0)\n",
    "    phase = os.listdir(os.path.join(write_path,'test_phase2'))\n",
    "    phase = natsorted(phase)\n",
    "    if not os.path.exists(os.path.join(Data_path,parent,foldername)):\n",
    "        os.makedirs(os.path.join(Data_path,parent,foldername))\n",
    "    if not os.path.exists(os.path.join(Data_path,parent,foldername,'pesq')):\n",
    "    #     print('creating pesq')\n",
    "        os.makedirs(os.path.join(Data_path,parent,foldername,'pesq'))\n",
    "    if not os.path.exists(os.path.join(Data_path,parent,foldername,'sdr')):\n",
    "        os.makedirs(os.path.join(Data_path,parent,foldername,'sdr'))\n",
    "    if not os.path.exists(os.path.join(Data_path,parent,foldername,'stoi')):\n",
    "        os.makedirs(os.path.join(Data_path,parent,foldername,'stoi'))\n",
    "    for filename1,filename2,filename4 in zip(inputs,phase,mixed):\n",
    "        print(filename1)\n",
    "        print(filename2)\n",
    "        print(filename4)\n",
    "        a = os.listdir(os.path.join(write_path,input_test,filename1))\n",
    "        b = os.listdir(os.path.join(write_path,'test_phase2',filename2))\n",
    "        print('blah')\n",
    "        c = os.listdir(os.path.join(write_path,'test_log2',filename4))\n",
    "        stoi_eval=[]\n",
    "        pesq_eval=[]\n",
    "        sdr=[]\n",
    "        stoi_mixed=[]\n",
    "        sdr_mixed=[]\n",
    "        if not os.path.exists(os.path.join(Data_path,parent,foldername,filename1)):\n",
    "            os.mkdir(os.path.join(Data_path,parent,foldername,filename1))\n",
    "        for filename11,filename22,filename33,filename44 in zip(a,b,clean,c):\n",
    "            X_log=np.loadtxt(os.path.join(write_path,input_test,filename1,filename11),delimiter=',')\n",
    "            X_phase=np.loadtxt(os.path.join(write_path,'test_phase2',filename2,filename22),delimiter=',')\n",
    "            target = np.loadtxt(os.path.normpath(os.path.join(write_path,'test_log','clean',filename33)),dtype='float32',delimiter=',')\n",
    "            framed_data=librosa.core.stft(target, n_fft=512, hop_length=256, win_length=512, window='hann')\n",
    "            abslt=np.absolute(framed_data)**2\n",
    "            dft_signal=np.log10(abslt+(1e-7*np.ones(np.shape(abslt))))\n",
    "            mixed_files=np.loadtxt(os.path.join(write_path,'test_log2',filename4,filename44),delimiter=',')\n",
    "            prediction = loaded_model.predict(X_log)\n",
    "            recon_out = reconstruct(prediction, X_phase)\n",
    "            recon_mixed = reconstruct(mixed_files, X_phase)\n",
    "            recon_clean = reconstruct(dft_signal.T, X_phase)\n",
    "#             sf.write(os.path.normpath(os.path.join(Data_path,parent,foldername,filename1)+'\\\\'+filename11.replace('.txt','')+'.wav'),recon_out,16000)\n",
    "            target = target[0:len(recon_out)]\n",
    "            #target = np.reshape(target,(1,len(recon_out)))\n",
    "            #recon_out=np.reshape(recon_out,(1,len(recon_out)))\n",
    "    #         pesq_eval.append(get_pesq(target, recon_out,16000))\n",
    "            sdr.append(mir_eval.separation.bss_eval_sources(target, recon_out, compute_permutation=False)[0][0])\n",
    "            stoi_eval.append(stoi(target, recon_out, 16000, extended=False))\n",
    "            sdr_mixed.append(mir_eval.separation.bss_eval_sources(target, recon_mixed, compute_permutation=False)[0][0])\n",
    "            stoi_mixed.append(stoi(target, recon_mixed, 16000, extended=False))\n",
    "        mean_stoi.append(np.mean(stoi_eval))\n",
    "        mean_stoi_mixed.append(np.mean(stoi_mixed))\n",
    "        mean_sdr.append(np.mean(sdr))\n",
    "        mean_sdr_mixed.append(np.mean(sdr_mixed))\n",
    "    mean_sdr2 = change_order(mean_sdr)\n",
    "    mean_stoi2 = change_order(mean_stoi)\n",
    "    mean_sdr_mixed2 = change_order(mean_sdr_mixed)\n",
    "    mean_stoi_mixed2 = change_order(mean_stoi_mixed)\n",
    "    np.savetxt(os.path.join(Data_path,parent,foldername,'sdr')+'\\\\'+'predictedsdr.txt',mean_sdr2, fmt='%1.4f')\n",
    "    np.savetxt(os.path.join(Data_path,parent,foldername,'sdr')+'\\\\'+'mixedsdr.txt',mean_sdr_mixed2, fmt='%1.4f')\n",
    "    np.savetxt(os.path.join(Data_path,parent,foldername,'stoi')+'\\\\'+'predictedstoi.txt',mean_stoi2, fmt='%1.4f')\n",
    "    np.savetxt(os.path.join(Data_path,parent,foldername,'stoi')+'\\\\'+'mixedstoi.txt',mean_stoi_mixed2, fmt='%1.4f')\n",
    "    if not os.path.exists(os.path.join(Data_path, parent, image, foldername)):\n",
    "        os.makedirs(os.path.join(Data_path, parent, image, foldername))\n",
    "    plt.plot([-9,-6,-3,0,3,6], mean_sdr2, 'r-o', [-9,-6,-3,0,3,6], mean_sdr_mixed2, 'b-o')\n",
    "    plt.gca().legend(('pred','mix'))\n",
    "    x=[-9,-6,-3,0,3,6]\n",
    "\n",
    "    plt.show\n",
    "    plt.savefig(os.path.normpath(os.path.join(Data_path, parent, image, foldername, 'sdr.png')))\n",
    "    plt.close()\n",
    "    plt.plot([-9,-6,-3,0,3,6], mean_stoi2, 'r-o', [-9,-6,-3,0,3,6], mean_stoi_mixed2, 'b-o')\n",
    "    plt.gca().legend(('pred','mix'))\n",
    "\n",
    "    plt.show\n",
    "    plt.savefig(os.path.normpath(os.path.join(Data_path, parent, image, foldername, 'stoi.png')))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pesq(reference, degraded, sample_rate=None, program='pesq'):\n",
    "    \"\"\" Return PESQ quality estimation (two values: PESQ MOS and MOS LQO) based\n",
    "    on reference and degraded speech samples comparison.\n",
    "    Sample rate must be 8000 or 16000 (or can be defined reading reference file\n",
    "    header).\n",
    "    PESQ utility must be installed.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(reference) or not os.path.isfile(degraded):\n",
    "        raise ValueError('reference or degraded file does not exist')\n",
    "    if not sample_rate:\n",
    "        import wave\n",
    "        w = wave.open(reference, 'r')\n",
    "        sample_rate = w.getframerate()\n",
    "        w.close()\n",
    "    if sample_rate not in (8000, 16000):\n",
    "        raise ValueError('sample rate must be 8000 or 16000')\n",
    "    import subprocess\n",
    "    args = [ program, '+%d' % sample_rate, reference, degraded  ]\n",
    "    pipe = subprocess.Popen(args, stdout=subprocess.PIPE)\n",
    "    out, _ = pipe.communicate()\n",
    "    last_line = out.split('\\n')[-2]\n",
    "    if not last_line.startswith('P.862 Prediction'):\n",
    "        raise ValueError(last_line)\n",
    "    return tuple(map(float, last_line.split()[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "sd.play(target,16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(recon_out,16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(recon_mixed,16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "loaded_model.get_weights()[7].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
